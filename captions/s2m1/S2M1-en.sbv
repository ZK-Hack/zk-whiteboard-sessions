0:00:07.000,0:00:10.000
S2 Module 1: What is Zero Knowledge (like, actually)? with David Wong

0:00:11.760,0:00:15.200
Nico: Welcome to Season 2 of 
the ZK Whiteboard Sessions.

0:00:15.200,0:00:16.760
I'm Nico, I'll be today's host.

0:00:16.760,0:00:18.800
And with me I have David from zkSecurity.

0:00:18.800,0:00:19.780
David: Hey guys.

0:00:19.780,0:00:22.480
Nico: If you have not yet, I 
encourage you to check out Season 1,

0:00:22.480,0:00:26.040
because we are going to be building 
upon what was learnt in those modules.

0:00:26.040,0:00:28.840
There's also a study club in the ZK Hack Discord

0:00:28.840,0:00:31.760
where we go over the sessions week after week.

0:00:31.760,0:00:35.040
Actually, it's by doing those 
sessions that we realized

0:00:35.040,0:00:38.240
a few things were missing or 
a few things needed updates.

0:00:38.240,0:00:40.360
So we're back with a new set of modules

0:00:40.360,0:00:44.800
sponsored by a grant from the Ethereum 
Foundation ZK Grants program.

0:00:44.800,0:00:47.600
And today's module is going 
to be about "What is ZK"?

0:00:47.600,0:00:50.920
And I mean, "What is zero knowledge?" 
The actual cryptographic property.

0:00:50.920,0:00:53.120
And this is something that's 
really important because,

0:00:53.120,0:00:55.840
in all the episodes we have, 
we didn't really cover this.

0:00:55.840,0:01:00.360
So, David, today we're going to go over 
the theory, some of the practice as well,

0:01:00.360,0:01:02.420
and see if our good friend, 
PLONK, is zero knowledge.

0:01:02.420,0:01:03.702
David: Yeah. Cool.

0:01:03.702,0:01:08.840
Yeah. So everybody always talks about ZKP, 
Zero Knowledge Proofs and these kind of things.

0:01:08.840,0:01:11.320
And the ZK is always kind of like mysterious

0:01:11.320,0:01:13.360
and it's almost like we 
don't really care about it.

0:01:13.360,0:01:17.720
So I guess we're going to dig 
more into what exactly it is.

0:01:17.720,0:01:22.220
The first thing we can talk about is sort 
of a high level, what is the API of ZK?

0:01:22.220,0:01:23.400
Nico: Sure.

0:01:24.480,0:01:29.920
So if you think of a prover and a verifier, 
all of these things and you really abstract it,

0:01:30.680,0:01:36.560
what they're really doing is that they're 
proving a program or a statement or whatever.

0:01:36.560,0:01:41.600
In our days and age, we think about programs 
because we're like general-purpose ZKP.

0:01:41.600,0:01:45.400
And so here we have like some 
-- let's say, some function.

0:01:46.240,0:01:50.760
And this function takes some arguments.

0:01:50.760,0:01:58.800
Maybe I'll write that bigger ARG2, 
arg1. Maybe put us some outputs.

0:01:58.800,0:02:00.800
And this is purely computational.

0:02:00.800,0:02:06.240
Like you're running that on your computer 
and maybe you want to prove to me that

0:02:06.240,0:02:09.815
running this function with these 
arguments gives this output. Right?

0:02:09.815,0:02:17.040
And so usually when we talk about ZK, ZK comes 
in place when you want to mask something.

0:02:17.040,0:02:19.382
Like you want to prove to me 
that you're computing this thing,

0:02:19.382,0:02:22.480
but you don't really want 
to show me these arguments.

0:02:23.160,0:02:26.200
So a typical example is like 
this is a Sudoku Solver.

0:02:26.200,0:02:31.120
This is like a grid of a Sudoku 
that's missing some squares.

0:02:31.120,0:02:34.000
And this is the actual 
solution, and this is like "true,

0:02:34.000,0:02:37.000
this is a good solution" and you're masking that.

0:02:37.000,0:02:37.860
Nico: Makes sense.

0:02:37.860,0:02:39.120
David: Hopefully that makes sense.

0:02:39.120,0:02:41.520
This is really --

0:02:41.520,0:02:44.960
I always tell people, if you want to 
think about ZK, don't think about ZK,

0:02:44.960,0:02:49.560
think about pure computation and then 
think about what you want to mask.

0:02:49.560,0:02:54.360
And you don't need to understand how ZK works, 
you can just think of it from a high level.

0:02:55.200,0:03:02.800
It seems like a lot of people sometimes care 
more about the succinctness of modern schemes.

0:03:02.800,0:03:06.000
So we don't really talk about 
ZK so much in modern schemes.

0:03:06.000,0:03:09.920
People tend to talk about zk-SNARKs or SNARKs.

0:03:09.920,0:03:13.080
Maybe I'll write it down.

0:03:13.080,0:03:16.640
And the succinctness comes from that S.

0:03:16.640,0:03:21.600
I don't know how to write "succinctness". 
I always mess it up, but I will try.

0:03:21.600,0:03:25.120
And people can correct me at home if they want.

0:03:25.120,0:03:28.600
And basically this says, okay, you're 
going to prove to me this computation,

0:03:29.600,0:03:36.920
but when I'm going to verify your proof, which 
is kind of a signature over that computation,

0:03:36.920,0:03:40.560
it's going to take me less time to 
verify it than it would have taken me to,

0:03:40.560,0:03:43.500
like if you send me the arguments 
to run the function myself.

0:03:43.500,0:03:44.300
Nico: I see.

0:03:44.300,0:03:46.800
David: Right? So there's kind of a --

0:03:46.800,0:03:50.080
Like ZKPs have really two interesting things.

0:03:50.080,0:03:51.280
You can mask some of the --

0:03:51.280,0:03:55.080
You can prove to me a computation, you 
can mask some of the inputs or outputs.

0:03:56.040,0:03:59.720
Again, here you can mask that or you can 
mask that, or you can mask whatever you want.

0:03:59.720,0:04:00.560
Nico: Sure.

0:04:01.680,0:04:05.160
Although it's not very useful 
if you mask everything.

0:04:05.720,0:04:12.170
But also you can -- there's a succinctness aspect 
where it's very cheap for me to verify a proof.

0:04:12.170,0:04:15.560
Nico: So succinctness and zero 
knowledge are two separate properties

0:04:15.560,0:04:18.700
and you can have one without the other, or --

0:04:18.700,0:04:19.840
David: Exactly, exactly.

0:04:19.840,0:04:23.360
Some schemes are not succinct, 
some schemes are not ZK.

0:04:23.360,0:04:25.520
And as we'll see, actually 
most schemes are not ZK,

0:04:25.520,0:04:29.040
and ZK is sort of like, you can 
add it at the end if you want,

0:04:29.040,0:04:32.160
either for free or like 
you have to think about it.

0:04:33.280,0:04:38.120
And maybe we should mention that a 
lot of schemes don't even use the ZK

0:04:38.120,0:04:42.220
like modern zk-Rollups or so-called zk-Rollups.

0:04:42.220,0:04:43.520
Nico: Are not ZK?

0:04:43.520,0:04:47.760
David: Are not really ZK because 
they don't actually mask anything.

0:04:47.760,0:04:52.920
They mostly care about compressing all that 
computation in a way that's easy to verify.

0:04:52.920,0:04:53.700
It's like -- yeah.

0:04:53.700,0:04:57.880
Nico: So should we define ZK? 
Like what do we mean? What is --

0:04:57.880,0:04:58.666
David: Okay. So --

0:04:58.666,0:04:59.400
Nico: -- it's property?

0:04:59.400,0:05:00.960
David: At a high level this is that.

0:05:00.960,0:05:05.640
But if we look at deeper -- 
there's a deeper meaning behind it.

0:05:05.640,0:05:09.360
And as cryptographers, we have to 
think about the deeper meaning.

0:05:10.200,0:05:14.800
So the way we can think about it is that--

0:05:14.800,0:05:18.880
You know, imagine I'm the 
prover and you're the verifier.

0:05:18.880,0:05:22.760
I want to prove something to you, but there's 
-- I really want to hide that stuff from you.

0:05:23.320,0:05:27.600
Like we can think of these schemes 
where usually that's what we do, right?

0:05:27.600,0:05:29.160
We're like communicating.

0:05:29.160,0:05:33.200
I'm sending you a message, you're sending 
me a message, I'm sending you a message.

0:05:33.200,0:05:35.080
We go back and forth.

0:05:35.080,0:05:38.800
Actually, a lot of very basic 
schemes are just three messages,

0:05:38.800,0:05:42.120
which are called "Sigma protocol", 
because of the shape of the Sigma.

0:05:43.000,0:05:49.200
And here I really want to prove something to you, 
but I don't want to, like I said, leak this thing.

0:05:50.800,0:05:57.520
And so the idea is that -- or a 
way that we try to theorize that,

0:05:57.520,0:06:03.760
which is kind of hard to understand 
actually, is that if I was talking to --

0:06:03.760,0:06:05.160
Maybe I can --

0:06:05.160,0:06:07.080
So I'm the prover, right?

0:06:07.080,0:06:08.000
Nico: Sure.

0:06:08.000,0:06:14.154
David: And I don't know if we're going to talk 
about soundness at some point, but this is --

0:06:14.154,0:06:14.793
Nico: Sure. I think --

0:06:14.793,0:06:16.720
David: Maybe I should mention it also.

0:06:16.720,0:06:19.960
But there's kind of competing 
properties of proof systems.

0:06:21.840,0:06:24.120
As the verifier, you want to 
make sure I'm not lying to you,

0:06:24.120,0:06:29.560
but as the prover, I want to make sure you're 
not getting information from me, right?

0:06:29.560,0:06:30.560
Nico: Makes sense.

0:06:30.560,0:06:39.040
David: And so as the prover 
-- or, sorry, as the verifier,

0:06:39.040,0:06:43.000
you want to see if you can distinguish 
between this wall where you're talking to me,

0:06:43.000,0:06:51.520
and you're trying to obtain information from me, 
or you're talking to what we call a 'simulator'.

0:06:51.520,0:06:53.780
So this is how we get into the theory of it.

0:06:53.780,0:06:54.640
Nico: Okay.

0:06:54.640,0:07:01.800
David: And if you can talk to a simulator that 
has no idea about the Sudoku solution or whatever,

0:07:01.800,0:07:06.720
and they give you the same result as if 
you were talking to me, a real prover,

0:07:06.720,0:07:09.960
then -- like you can't really tell if 
you're talking to me or to a simulator

0:07:09.960,0:07:14.640
that doesn't even know about the actual -- 
we should call it witness at this point,

0:07:16.000,0:07:18.640
then the scheme is zero knowledge.

0:07:18.640,0:07:20.200
So that's my introduction to it.

0:07:20.200,0:07:25.000
Maybe it doesn't make sense, but I wanted 
to introduce the idea of simulator.

0:07:25.000,0:07:30.240
Nico: So the intuition behind this is even 
though the simulator doesn't know the witness,

0:07:30.240,0:07:31.420
we can have this interaction?

0:07:31.420,0:07:32.320
David: Right.

0:07:32.320,0:07:35.840
And I'll write "witness" here 
because we just used the word.

0:07:36.400,0:07:38.960
So witness is the stuff that we're trying to mask.

0:07:42.280,0:07:46.120
So maybe I'll write the API of a simulator.

0:07:46.880,0:07:51.160
But imagine that this argument is 
actually not ZK, like it's public,

0:07:51.160,0:07:56.040
we say that usually this is the statements.

0:07:56.040,0:08:01.920
So a statement usually is what's known in public 
and the witness is what you're trying to mask.

0:08:01.920,0:08:08.200
And so the simulator, let's say S 
usually just take the statements --

0:08:08.200,0:08:11.760
usually x is the statement, w is 
the witness, doesn't really matter,

0:08:11.760,0:08:15.040
usually just take the statements.

0:08:15.040,0:08:19.920
Whereas a prover, on the other hand 
usually takes a statement and a witness.

0:08:19.920,0:08:24.160
So "Sudoku grid" and "Sudoku solution".

0:08:24.160,0:08:29.440
And so you're thinking if I 
can, sort of as a verifier,

0:08:30.040,0:08:32.880
just talk to a simulator that doesn't 
know anything about the witness,

0:08:32.880,0:08:37.960
and it looks the same as with the prover, 
then when I interact with a prover,

0:08:37.960,0:08:39.360
I don't really learn anything either.

0:08:39.360,0:08:42.280
Nico: That makes sense.

0:08:42.280,0:08:44.760
Should we maybe see a concrete 
example of a simulator?

0:08:44.760,0:08:50.600
David: A good example to see these kind 
of things is to look at the Schnorr --

0:08:50.600,0:08:51.540
Is this how you write "Schnorr"?

0:08:51.540,0:08:52.600
Nico: Correct. Yeah.

0:08:52.600,0:08:55.720
David: Schnorr identity protocol.

0:08:58.200,0:09:04.800
And Schnorr identity protocol is something pretty 
simple that is at the base of Schnorr signatures.

0:09:04.800,0:09:11.240
And actually ECDSA signatures sort of 
follow the same -- like a similar pattern.

0:09:12.280,0:09:16.940
And this is a proof, a zero knowledge 
proof of a discrete logarithm.

0:09:16.940,0:09:18.000
Nico: Okay.

0:09:18.000,0:09:19.760
So here in this setting,

0:09:19.760,0:09:28.000
the prover knows the discrete logarithm 
of a value Y. So we'll call that x.

0:09:28.000,0:09:31.942
And they want to prove to the verifier, -- so 
I'm the prover, you're the verifier, right?

0:09:31.942,0:09:31.953
Nico: Cool.

0:09:31.953,0:09:35.280
David: They want to prove that 
they know the x here. Right?

0:09:35.280,0:09:38.880
So the way it works -- this is a 
three-step protocol, the Sigma protocol.

0:09:38.880,0:09:45.060
The way it works is that you usually 
send -- you commit to a value.

0:09:45.060,0:09:46.833
Nico: Small r maybe?

0:09:46.833,0:09:48.960
David: I'll call it r. Yeah.

0:09:48.960,0:09:54.640
You commit to a value that you 
generated hopefully randomly,

0:09:54.640,0:10:02.160
and then you receive a challenge from 
the verifier that hopefully is random,

0:10:02.160,0:10:03.840
and we'll talk more about that.

0:10:04.600,0:10:13.400
And then you send something which is, let's 
see if I can remember it, r + c . x.

0:10:13.400,0:10:15.520
So that's the value you can 
compute as the prover because

0:10:15.520,0:10:20.360
you know x times the challenge 
plus the value you committed.

0:10:21.440,0:10:26.480
And this protocol is sound and complete, 
as we say in zero knowledge proof,

0:10:26.480,0:10:27.720
meaning that it works.

0:10:30.000,0:10:32.280
If I know the value x, I can 
prove it to you it's complete,

0:10:32.280,0:10:35.220
and it's sound, I cannot lie to 
you if I don't know the value x.

0:10:35.220,0:10:37.360
Nico: Are we missing a verification step here?

0:10:37.360,0:10:40.160
David: Yeah. What does the verifier do at the end?

0:10:40.160,0:10:42.080
Let's see also if I can remember that.

0:10:42.080,0:10:47.680
So z obviously is something that you 
need to raise. So they will raise z.

0:10:47.680,0:10:51.800
And they will check if it's equal to 
-- there's many ways to do that check,

0:10:51.800,0:11:01.754
but that's a way you can do it. 
yᶜ. Because yᶜ --

0:11:01.754,0:11:02.920
Nico: Plus r. No?

0:11:02.920,0:11:08.840
David: We can -- times R, right?

0:11:08.840,0:11:09.760
Let's open it.

0:11:09.760,0:11:23.120
So yᶜ is gˣᶜ . gʳ
And so -- yeah, which is z; is it?

0:11:23.120,0:11:26.680
All right, we got it right on the first try.

0:11:27.280,0:11:32.840
Okay. So that scheme is -- you know, it's 
nice, it works, it's using Schnorr signatures.

0:11:32.840,0:11:35.880
Let's see why it's ZK or 
let's see why it's not ZK.

0:11:35.880,0:11:37.080
Nico: Sounds good.

0:11:37.080,0:11:41.840
David: Okay. Let's wipe that.

0:11:41.840,0:11:44.120
So we're going to take the idea of a simulator,

0:11:44.120,0:11:48.920
and here what the simulator wants to 
do, or you as like you're the verifier,

0:11:48.920,0:11:53.440
you're going to call that simulator 
and see if you can make it work.

0:11:53.440,0:11:58.920
And basically the way it works here 
is that you want to form a transcript

0:11:58.920,0:12:04.960
that looks like Message₁, Message₂, Message₃,

0:12:04.960,0:12:12.954
which are the first point, the challenge 
and that z. And you want it to verify --

0:12:12.954,0:12:13.640
Nico: This equation?

0:12:13.640,0:12:15.000
David: Exactly.

0:12:15.640,0:12:21.240
Even though the simulator, who produces 
that doesn't know the x. Right?

0:12:21.720,0:12:26.840
So the way they do it is 
that basically they go out of order.

0:12:26.840,0:12:32.440
They know that the verifier is 
going to sample some random value.

0:12:32.440,0:12:37.320
So they choose a random c in advance,

0:12:37.320,0:12:43.680
and then they choose a random 
z actually, they don't care.

0:12:43.680,0:12:45.960
They're so powerful. They don't care.

0:12:45.960,0:12:51.920
And then they're going to say -- they're going 
to know that they did things out of order.

0:12:51.920,0:12:56.640
They're going to say that m1 or whatever R is --

0:12:56.640,0:13:00.120
Okay. Let's think about it. So you 
want that equation to work, right?

0:13:00.120,0:13:01.120
Nico: Yeah.

0:13:01.120,0:13:04.080
David: And --

0:13:04.080,0:13:08.880
Nico: So we know this and we 
know this, so can we set this.

0:13:08.880,0:13:15.880
David: Right. So you want r -- oh, sorry. It's 
big R, right? You want big R to be equal to -

0:13:15.880,0:13:27.040
We can look at that equation here, to be equal 
to gᶻ divided by yᶜ or multiplied by y⁻ᶜ.

0:13:27.040,0:13:34.200
And you know this value. You 
know everything here, basically,

0:13:34.200,0:13:37.860
and so you can compute that 
and the equation will check.

0:13:37.860,0:13:38.780
Nico: That makes sense.

0:13:38.780,0:13:40.800
David: Does that make sense? Yeah.

0:13:42.080,0:13:43.280
And so that's it.

0:13:43.280,0:13:46.520
That's the transcript that 
the simulator can produce,

0:13:46.520,0:13:48.920
and they didn't know the witness.

0:13:48.920,0:13:52.480
They just formed this R out of nowhere.

0:13:52.480,0:13:54.480
You can verify these transcripts

0:13:54.480,0:13:58.752
and it doesn't really tell you 
anything about any witness, and --

0:13:58.752,0:13:59.200
Nico: I see.

0:13:59.200,0:14:01.160
David: And basically that's the idea.

0:14:01.160,0:14:04.720
Nico: And so this is why the Schnorr 
identity protocol is zero knowledge,

0:14:04.720,0:14:06.480
because we are able to produce this?

0:14:06.480,0:14:11.880
David: So it's not zero knowledge per 
se, because here we made an assumption.

0:14:11.880,0:14:19.000
We actually made the assumption that the 
challenge here is sampled uniformly --

0:14:19.000,0:14:20.360
from a uniform distribution.

0:14:21.080,0:14:22.820
And so that's not always true.

0:14:22.820,0:14:23.520
Nico: Right.

0:14:23.520,0:14:27.840
David: Verifiers might get nasty 
and try to learn stuff from you

0:14:27.840,0:14:33.320
and might send you specific values to 
try and leak information from your data.

0:14:33.320,0:14:41.080
And so we made an assumption in this 
case which we called Honest -- one n,

0:14:41.840,0:14:47.600
Honest-Verifier ZK.

0:14:47.600,0:14:52.560
And so usually we write HVZK.

0:14:52.560,0:14:55.200
And so it's important to note

0:14:55.200,0:14:59.040
because when you want to write 
proofs which are simulator-based,

0:14:59.040,0:15:02.560
you want to try and understand 
what can the simulator do.

0:15:02.560,0:15:06.040
If you always start with an 
honest verifier assumption,

0:15:06.040,0:15:11.960
in which case the verifier can choose 
these challenges by themselves,

0:15:11.960,0:15:16.440
or just say that they received 
all the challenges in advance

0:15:16.440,0:15:18.360
and they know exactly what 
the challenges look like.

0:15:18.360,0:15:20.960
These are two similar models.

0:15:21.560,0:15:24.720
But if you're -- usually we don't --

0:15:24.720,0:15:26.080
I mean, there's two camps.

0:15:27.120,0:15:31.580
One camp doesn't really like the HVZK, the 
Honest Verifier ZK, because they can --

0:15:31.580,0:15:35.840
maybe there's some attacks where they 
can leak things from your witness.

0:15:37.840,0:15:40.560
And maybe we can either both ways now.

0:15:40.560,0:15:43.800
We can either talk about that or we can talk about

0:15:43.800,0:15:47.440
why actually Honest Verifier 
ZK is okay these days.

0:15:47.440,0:15:50.560
Nico: So I do have one question 
before we jump into those topics.

0:15:50.560,0:15:54.880
It's what prevents a malicious 
prover from doing exactly this,

0:15:54.880,0:15:57.560
and proving something without 
knowledge of a witness?

0:15:57.560,0:16:00.000
David: So this doesn't break the soundness,

0:16:00.000,0:16:00.840
very good question,

0:16:00.840,0:16:03.380
because here we went out of order.

0:16:03.380,0:16:03.840
Nico: Right.

0:16:03.840,0:16:05.200
David: Like we knew the challenge in advance,

0:16:05.200,0:16:09.720
so we created that R after knowing the challenge.

0:16:09.720,0:16:12.920
Whereas these schemes are 
really a commit and reveal --

0:16:12.920,0:16:16.600
well, there's no reveal actually, but 
they're commits and then receive a challenge.

0:16:17.400,0:16:21.320
And in this case it's important 
that you're following that order.

0:16:21.320,0:16:22.310
Nico: Okay.

0:16:22.310,0:16:28.920
David: Yeah. So honest verifier, do 
we want that, do we not want that?

0:16:29.800,0:16:33.280
If we're doing an interactive 
protocol, it really matters.

0:16:33.280,0:16:39.320
And so in that sense we don't want the verifier to 
send us malicious challenges that can leak stuff.

0:16:39.320,0:16:41.000
And so it turns out that --

0:16:41.000,0:16:44.880
for example, in this example 
the Schnorr ID protocol,

0:16:44.880,0:16:49.080
this is not dishonest verifier ZK 
because there are some issues here

0:16:49.080,0:16:52.160
and we don't actually know 
how to write a simulator

0:16:53.880,0:16:57.600
that will show you something that 
you can verify and that works.

0:16:57.600,0:17:04.000
And the reason is that if we assume 
that this might not be uniformly random,

0:17:04.000,0:17:09.600
then the simulator basically has to 
guess what the challenge will be.

0:17:09.600,0:17:14.480
So they are at this step, they have to 
produce some R while guessing the c.

0:17:14.480,0:17:17.560
They come here and then they call the verifier.

0:17:17.560,0:17:24.240
So we say that the simulator here 
has oracle access to the verifier.

0:17:25.120,0:17:28.400
And so they will see that the challenge 
is not actually what they thought about

0:17:28.400,0:17:32.120
because probably the sample space is pretty large.

0:17:32.120,0:17:34.560
And so they go back and they retry.

0:17:34.560,0:17:40.800
And they can do that many times, but the idea is 
that they're bounded, their runtime is bounded,

0:17:40.800,0:17:46.980
and so they most likely will never find a 
challenge that never guess the actual challenge.

0:17:46.980,0:17:47.660
Nico: I see.

0:17:47.660,0:17:49.480
David: If they could guess the actual challenge,

0:17:49.480,0:17:51.900
then it probably would mean 
that this scheme is not secure.

0:17:51.900,0:17:53.480
Nico: That makes sense.

0:17:53.480,0:17:58.480
David: And so -- well, actually I'm going 
to backtrack on that, but you'll see why.

0:17:58.480,0:18:04.640
So a way to make this actually "dishonest 
verifier ZK" or just plain ZK as we say,

0:18:04.640,0:18:09.240
is to have the challenge c 
sample from a very small domain.

0:18:09.240,0:18:10.880
So actually if you --

0:18:10.880,0:18:12.080
Maybe I'll use a different color.

0:18:12.080,0:18:14.320
No. All right. Just keep on that.

0:18:14.320,0:18:22.200
If you sample c from 0 or 1 like a bit, 
then we can prove that this is plain ZK

0:18:22.200,0:18:28.627
because now the simulator 
can, with good estimates --

0:18:28.627,0:18:28.858
Nico: Try to guess --

0:18:28.858,0:18:35.040
David: Guess if it's going to be 0 or 1, 
if it's with expectation of two tries.

0:18:36.480,0:18:38.520
So maybe the first time 
they're not going to get it,

0:18:38.520,0:18:40.800
but the second time they're expected to get it.

0:18:40.800,0:18:43.400
And that's fine because the simulator can do that.

0:18:43.400,0:18:48.880
They are a polynomial bounded algorithm.

0:18:48.880,0:18:52.640
Nico: Does this come at some kind of 
cost? Maybe a penalty on soundness?

0:18:52.640,0:18:53.360
David: Yeah.

0:18:53.360,0:18:54.560
So it kind of sucks, right?

0:18:54.560,0:18:58.720
Because the real prover in that case has basically

0:18:59.760,0:19:03.600
1 out of 2 chance to guess the 
challenge correctly as well.

0:19:04.160,0:19:05.960
And so it sucks because they might --

0:19:05.960,0:19:09.560
half of the time, even if they don't know 
the witness, they'll correctly prove.

0:19:09.560,0:19:14.280
So usually in these schemes what you want 
to do is repeat it many, many, many times.

0:19:14.280,0:19:16.920
Because here the soundness is 
like, well, I guess 1 over 2.

0:19:16.920,0:19:21.000
But if you repeat it many, 
many times, you decrease the --

0:19:21.000,0:19:23.640
the prover will have to guess the correct c like

0:19:23.640,0:19:26.880
100 times in a row without 
mistakes, and that's harder.

0:19:26.880,0:19:28.720
Or I don't know how many times.

0:19:28.720,0:19:32.320
Nico: So you said Schnorr 
signatures are based on this idea.

0:19:32.320,0:19:34.640
I'm guessing we're not doing 
this with our Schnorr signatures.

0:19:34.640,0:19:35.920
David: Right. Let's --

0:19:35.920,0:19:37.800
We're not repeating the protocol many times.

0:19:37.800,0:19:38.120
Yeah.

0:19:38.120,0:19:40.080
That would suck.

0:19:40.080,0:19:44.680
So in Schnorr signatures, we 
have a non-interactive protocol,

0:19:44.680,0:19:47.440
which I guess I'm going to 
sort of not mention too much.

0:19:47.440,0:19:52.480
But it's basically I can create a proof there 
is no interaction. You can just verify it.

0:19:52.480,0:20:00.560
And to do that we use a transformation called 
Fiat–Shamir, because there were two guys,

0:20:00.560,0:20:05.960
one was called Fiat, one was called Shamir, if I 
remember correctly, but I don't think I was born,

0:20:05.960,0:20:09.640
and they invented this thing where basically,

0:20:09.640,0:20:16.360
if you know these are public coin messages, 
which means that they're random and public.

0:20:16.360,0:20:17.800
Nico: From a big distribution, right?

0:20:17.800,0:20:18.780
David: From a big distribution.

0:20:18.780,0:20:19.760
Nico: Cool.

0:20:19.760,0:20:21.240
David: But I would -- yeah.

0:20:22.560,0:20:25.960
If you know -- so we call them "public coin 
messages", but it doesn't really matter.

0:20:25.960,0:20:28.640
But it's just the term that we 
use. It's public randomness.

0:20:29.400,0:20:33.520
Then you can replace these 
things by a hash function.

0:20:33.520,0:20:34.760
Basically, that's the idea.

0:20:35.440,0:20:39.240
But of course, in theory we 
call them "random oracles".

0:20:40.280,0:20:43.493
And this whiteboard is starting to get crowded --

0:20:43.493,0:20:47.200
Nico: Crowded, yeah.
David: But it's fine.

0:20:47.200,0:20:51.760
And so when we start using hash functions --

0:20:54.080,0:20:58.920
Right now we're still in the ideal model. 
So we're still using ideal constructions.

0:20:58.920,0:21:02.400
But when we're going to instantiate 
these, usually we use hash functions.

0:21:02.400,0:21:05.520
And so once we switch to these things,

0:21:05.520,0:21:10.280
we say that we're in the 
random oracle model or ROM.

0:21:11.200,0:21:12.720
This is kind of the lingo.

0:21:12.720,0:21:15.080
It doesn't matter too much, but it's good to know.

0:21:15.080,0:21:15.710
Nico: Yeah.

0:21:15.710,0:21:22.040
David: And so what we do here is that we replace 
any interaction from the verifier by hashes.

0:21:22.040,0:21:24.280
In these Sigma protocols, it's pretty easy.

0:21:24.280,0:21:26.800
You just hash that first part.

0:21:26.800,0:21:30.160
So a transcript would look like -- 
like you would remove the challenge.

0:21:30.160,0:21:34.640
And when you would verify these 
transcripts, you would basically use --

0:21:34.640,0:21:39.920
Here, instead of this c, you 
would use a hash of R, right?

0:21:39.920,0:21:42.000
Nico: And maybe y, I'm guessing.

0:21:42.000,0:21:43.280
David: And maybe the statement.

0:21:43.280,0:21:44.880
And so that's where it gets tricky.

0:21:44.880,0:21:48.080
So like people never know 
like what are you supposed

0:21:48.080,0:21:52.400
to include in the Fiat–Shamir transformation.

0:21:52.400,0:21:54.120
And usually you want to include --

0:21:54.120,0:21:57.400
The answer is you want to include 
as many things as possible.

0:21:57.400,0:22:00.600
And I believe there were actually some problem

0:22:00.600,0:22:03.040
when people instantiated signatures where they

0:22:03.040,0:22:05.520
didn't include the public 
key, which is the y here.

0:22:06.560,0:22:12.120
Famously EdDSA included the 
public key, so they were less --

0:22:12.120,0:22:15.080
Some contrived attacks were less annoying.

0:22:15.600,0:22:16.760
But yeah.

0:22:16.760,0:22:18.640
And so it may be worth mentioning,

0:22:18.640,0:22:22.760
but in these days and age, 
we have more modern SNARKs.

0:22:22.760,0:22:27.280
And they're sort of like Sigma 
protocols, but they're much longer,

0:22:27.280,0:22:29.000
they have more challenges.

0:22:29.000,0:22:31.920
And so here the Fiat–Shamir 
transformation is a bit trickier.

0:22:31.920,0:22:34.000
You have to constantly hash --

0:22:34.000,0:22:39.640
You have to continuously hash the transcript 
up to that point to create these challenges.

0:22:39.640,0:22:42.400
And there's a lot of bugs in these kind of things.

0:22:42.400,0:22:47.240
Nico: So in this case, we've replaced our verifier 
by the random oracle or the hash function.

0:22:47.240,0:22:51.080
Does that mean it now behaves 
honestly and this is enough?

0:22:51.080,0:22:53.720
David: Yeah. So the idea here is that

0:22:55.200,0:23:00.520
in this model you can either say 
the Fiat–Shamir stuff is a compiler,

0:23:00.520,0:23:03.880
and if we're in the honest 
verifier model, then it's fine.

0:23:03.880,0:23:06.160
Like we're not in ZK.

0:23:06.160,0:23:06.780
Nico: Right.

0:23:06.780,0:23:10.120
David: It's secure. Or you 
can say that you're in --

0:23:11.280,0:23:19.360
You can analyze this in a different way 
where you can say that you're in the EP ROM.

0:23:19.360,0:23:21.714
Let's write it here. EP ROM.

0:23:21.714,0:23:23.240
Nico: What does E and P stand for?

0:23:23.240,0:23:33.760
David: So E is for Explicit Programmable or 
Explicitly Programmable, or you know, English --

0:23:33.760,0:23:37.320
Two M, I believe.

0:23:39.480,0:23:41.520
Explicitly programmable.

0:23:41.520,0:23:45.560
And that means that basically, 
once you reach the challenge

0:23:45.560,0:23:48.800
where you're supposed to 
do a hash of, let's say, R,

0:23:48.800,0:23:50.840
let's include the statements, because YOLO.

0:23:52.120,0:23:57.320
And once you do that, once you have 
your call to that random oracle,

0:23:57.320,0:23:58.840
you can basically --

0:23:58.840,0:24:05.140
the simulator will basically choose -- will 
program the random oracle and choose the answer.

0:24:05.140,0:24:05.760
Nico: Right.

0:24:05.760,0:24:09.040
David: And so they basically have a superpower.

0:24:09.560,0:24:12.980
And without that superpower, they wouldn't 
be able to create a valid transcript.

0:24:12.980,0:24:14.320
Nico: Right.

0:24:14.320,0:24:17.820
Right. Because we needed to know 
this value before knowing R?

0:24:17.820,0:24:18.880
David: Right.

0:24:18.880,0:24:21.200
Nico: Interesting.

0:24:22.520,0:24:31.040
David: So far I haven't really talked about 
the CRS stuff and there's more superpowers,

0:24:31.040,0:24:36.900
but maybe before we get there, maybe let's talk 
about the different flavors of zero knowledge.

0:24:36.900,0:24:37.640
Nico: Sounds good.

0:24:37.640,0:24:42.520
David: And then we can talk 
about our famous SNARKs

0:24:42.520,0:24:47.080
and how simulators can do things in that world,

0:24:47.080,0:24:49.740
rather than Sigma protocols, 
which are fairly simple.

0:24:49.740,0:24:51.480
Nico: Sounds good.

0:24:51.480,0:24:56.400
David: So what are the three flavors of ZK?

0:24:56.400,0:25:03.200
We talk about ZK as perfect ZK. That's a 
flavor most people like. This is chocolate.

0:25:03.200,0:25:12.480
And the second flavor of ZK 
is -- yeah, statistical ZK.

0:25:12.480,0:25:16.960
And the third flavor of ZK is computational ZK.

0:25:16.960,0:25:24.160
Nico: And in all these cases, we get honest 
verifier and malicious verifier variants?

0:25:24.160,0:25:27.200
David: Yeah. So you can combine all of that.

0:25:27.200,0:25:28.800
In every case, there's --

0:25:28.800,0:25:31.120
So you can do all the combinations of ice cream.

0:25:31.120,0:25:32.080
Nico: Choose my toppings.

0:25:32.080,0:25:32.880
David: Yeah.

0:25:32.880,0:25:37.400
And this is probably like 
vanilla or something like that.

0:25:37.400,0:25:39.440
We don't like this one too much.

0:25:39.440,0:25:40.640
I mean, it depends on people.

0:25:41.640,0:25:43.020
But that's fine. It doesn't mean it's bad.

0:25:43.020,0:25:45.700
Nico: So what's the differences 
between the -- our three flavors?

0:25:45.700,0:25:49.380
David: So to understand the difference, we 
sort of have to look into probabilities.

0:25:49.380,0:25:50.320
Nico: Okay.

0:25:50.320,0:25:52.800
David: And so I've been talking about simulators

0:25:52.800,0:25:56.240
and how a verifier can interact with a simulator

0:25:56.240,0:26:00.760
and how the simulator can have Oracle 
access to the verifier and stuff like that.

0:26:00.760,0:26:03.880
Maybe it's a bit confusing. 
So let's put it in writing.

0:26:04.960,0:26:07.080
As usual in cryptography, we play games

0:26:07.080,0:26:11.440
and then we check the 
probabilities of these games.

0:26:11.440,0:26:16.280
So I can never remember this one. So 
let's see if I get it on the first try.

0:26:16.280,0:26:21.840
But here we're playing a game where 
the verifier is sort of the adversary.

0:26:21.840,0:26:24.680
Like they want to check if they 
really can talk to the simulator

0:26:24.680,0:26:28.040
and talk to the prover and 
see if there's a difference.

0:26:29.400,0:26:35.160
So we get an instance and a witness, or vice 
versa -- sorry, a witness and an instance.

0:26:35.160,0:26:36.920
We get them from the adversary.

0:26:37.920,0:26:45.360
And then we're going to 
get a random bit at random.

0:26:45.360,0:26:47.440
And then we're going to say,

0:26:47.440,0:26:58.240
this proof is created by a prover on the 
witness and statements if b equals 0,

0:26:59.040,0:27:04.120
or by the simulator if b equals 1.

0:27:04.120,0:27:05.560
So basically we're playing this game,

0:27:05.560,0:27:09.360
but we don't know if we're talking to the 
prover or we're talking to the simulator.

0:27:09.360,0:27:09.960
Nico: Right.

0:27:09.960,0:27:11.720
David: And then the adversary --

0:27:11.720,0:27:19.520
And I'm kind of simplifying here, the adversary 
usually take more inputs, but who cares? YOLO.

0:27:19.520,0:27:30.440
And now the adversary takes the proof and the 
statements and responds with, let's say, b prime.

0:27:31.280,0:27:33.440
And basically the adversary 
is trying to guess, right?

0:27:33.440,0:27:37.680
If they're talking to the prover or the simulator, 
they're trying to distinguish, actually.

0:27:37.680,0:27:39.980
So you might see a d here in some definition.

0:27:39.980,0:27:40.680
Nico: Right.

0:27:40.680,0:27:47.080
David: And here we want to check the probability 
that they actually made a good guess.

0:27:47.080,0:27:48.640
Does that make sense?

0:27:48.640,0:27:49.300
Nico: Yeah.

0:27:49.300,0:27:50.240
David: Does that make sense?

0:27:52.240,0:27:59.360
I might be forgetting some 
details, but that's the idea.

0:27:59.360,0:28:03.720
So let's look at it again.

0:28:04.560,0:28:07.880
Adversary chooses the instance and witness,

0:28:08.960,0:28:12.914
and either the prover or the simulator creates a 
proof and then they have to try and figure out --

0:28:12.914,0:28:17.920
Nico: Figure out which one. Okay. So 
this probability should be, I guess --

0:28:17.920,0:28:19.880
David: What's the best case?

0:28:19.880,0:28:22.080
Nico: The best case for us?

0:28:22.080,0:28:25.580
Well, One half, right? 
We're trying to guess a bit.

0:28:25.580,0:28:26.180
David: Right.

0:28:26.180,0:28:27.580
Nico: So it's a 50-50 chance.

0:28:27.580,0:28:28.400
David: Exactly.

0:28:28.400,0:28:31.887
So if this probability is one half --

0:28:31.887,0:28:31.910
Nico: We're very happy.

0:28:31.910,0:28:35.900
David: Or is exactly one half, 
actually, we're in the perfect world.

0:28:35.900,0:28:36.600
Nico: Right.

0:28:36.600,0:28:37.800
David: All right.

0:28:37.800,0:28:41.560
This is, we're happy.

0:28:41.560,0:28:48.600
If it's around one half, up 
to some negligible value,

0:28:48.600,0:28:51.080
I'll just write it like that, I guess,

0:28:51.080,0:28:55.320
but usually there's better ways to 
write it, but it doesn't really matter.

0:28:55.320,0:29:00.840
If it's almost close to one half, 
we say that it's statistical.

0:29:02.760,0:29:09.200
And now if it's almost close to one 
half, but the adversary is bounded,

0:29:09.200,0:29:14.144
because so far we basically assume that 
the adversary was unbounded up to --

0:29:14.144,0:29:14.600
Nico: Unlimited power.

0:29:14.600,0:29:15.680
David: Unlimited power.

0:29:16.240,0:29:17.840
So that's also interesting.

0:29:19.040,0:29:21.360
But if now we're limiting 
the power of the adversary,

0:29:21.360,0:29:26.520
which is actually not too bad of 
an assumption in the real world,

0:29:26.520,0:29:32.000
because computers are bounded and so on, then 
we say that we're in the computational ZK.

0:29:32.000,0:29:35.620
Nico: Okay. I mean, things like discrete 
log are computational, right? So.

0:29:35.620,0:29:36.194
David: Yeah. So --

0:29:36.194,0:29:37.400
Nico: We might as well keep going.

0:29:37.400,0:29:38.760
David: Yeah, exactly.

0:29:39.640,0:29:44.880
So if you look at how different proofs 
are created or different attacks,

0:29:44.880,0:29:49.240
you can see that sometimes the 
adversary will be able to compute this.

0:29:49.240,0:29:51.380
And so these proofs are usual in these models.

0:29:51.380,0:29:53.560
Nico: Wow, okay.

0:29:53.560,0:29:58.040
So, David, I wanted to ask, 
how does this now apply to,

0:29:58.040,0:30:00.640
I guess protocols that we're more 
familiar with in this series?

0:30:00.640,0:30:02.300
Something like PLONK, let's say?

0:30:02.300,0:30:05.160
David: So, I guess --

0:30:05.160,0:30:07.114
Yeah. Let me make some room on the --

0:30:07.114,0:30:07.680
Nico: On the side?

0:30:07.680,0:30:09.680
David: The whiteboard.

0:30:09.680,0:30:12.720
We don't care about Schnorr 
because that's a Sigma,

0:30:13.360,0:30:17.120
and we're talking about PLONK or modern SNARKs.

0:30:17.120,0:30:18.160
Nico: Yeah.

0:30:18.160,0:30:22.160
David: So there's a few different ways to do ZK

0:30:22.160,0:30:28.160
or to try to create these --
send proofs with simulators.

0:30:28.160,0:30:30.880
But of course, things are more 
complex, we have a lot of interaction,

0:30:30.880,0:30:35.680
we have a lot of messages, like 
in the transcripts at the end.

0:30:36.720,0:30:40.560
So it's kind of hard to explain 
everything here on the whiteboard session,

0:30:40.560,0:30:44.040
but the thing we can do is 
simplify what PLONK looks like

0:30:44.040,0:30:46.160
or what these protocols looks like.

0:30:46.160,0:30:51.400
And if you look essentially at a proof in PLONK,

0:30:51.400,0:30:56.680
what it looks like is an array of commitments,

0:30:56.680,0:31:01.160
like I don't know, c₁, c₂, c₃, etc,

0:31:01.160,0:31:08.560
and an array of evaluations, e₁, e₂, e₃, etc.

0:31:08.560,0:31:11.640
Is there more to these schemes?

0:31:11.640,0:31:12.640
I don't think so.

0:31:12.640,0:31:18.700
But I believe it's commitments, polynomial 
commitments and evaluation at some points.

0:31:18.700,0:31:20.920
Nico: That makes sense.

0:31:20.920,0:31:25.200
David: And so when we look at 
that, the idea is that it's --

0:31:25.200,0:31:31.200
or maybe an insight is that it's easier to 
make this ZK if these things look random.

0:31:31.200,0:31:34.120
The more random these things 
look like, the more ZK it is.

0:31:34.720,0:31:40.740
If you imagine that all of these things are 
purely, uniformly random, then it's purely ZK.

0:31:40.740,0:31:44.360
Nico: Yeah. Well, the simulator 
can just put out random stuff.

0:31:44.360,0:31:45.000
David: Exactly.

0:31:45.000,0:31:47.360
As the simulator, you just 
pick random stuff and --

0:31:47.360,0:31:47.553
Nico: Cool.

0:31:47.553,0:31:50.960
David: Exactly. But if you do that, 
then the scheme is not very sound,

0:31:50.960,0:31:54.034
because then if everything's 
random, how do you even --

0:31:54.034,0:31:56.640
Nico: Because we still need to 
pass the verification step, right?

0:31:56.640,0:31:57.520
David: Right, right.

0:31:57.520,0:31:57.840
Nico: Okay.

0:31:57.840,0:32:00.720
David: But if you pass the verification 
step just by choosing random values,

0:32:00.720,0:32:04.880
then the prover can do the 
same, and then what's the point?

0:32:04.880,0:32:06.680
Nico: Fair

0:32:07.280,0:32:09.240
David: Okay. So let's look at the commitments first,

0:32:09.240,0:32:11.320
and then we'll look at the evaluations.

0:32:11.840,0:32:14.400
So you have different types of commitments.

0:32:14.400,0:32:19.600
We have KZG, Pedersen commitments, 
you can use hashes and so on.

0:32:19.600,0:32:24.520
And so here, to make commitments look random,

0:32:24.520,0:32:27.260
we want to look at the hiding 
property of commitments.

0:32:27.260,0:32:27.840
Nico: Okay.

0:32:27.840,0:32:36.840
David: So maybe let me write 
that -- hiding commitments.

0:32:36.840,0:32:39.320
And what does it mean that a commitment is hiding?

0:32:39.320,0:32:42.640
By the way, commitments have to be 
binding or they have different properties,

0:32:42.640,0:32:44.480
but I'm not going to say anything about that.

0:32:44.480,0:32:46.800
I'm only going to talk about hiding.

0:32:46.800,0:32:52.000
Hiding basically means that it looks more 
random and it hides what's committed.

0:32:52.760,0:32:56.080
Remember earlier we were talking about 
commitments with the Schnorr protocol

0:32:56.080,0:32:59.800
by just hiding stuff in the exponents.

0:33:00.760,0:33:04.720
But here, we're going to talk about 
maybe simpler commitments to start with.

0:33:04.720,0:33:06.400
We can talk about hashes.

0:33:06.400,0:33:07.760
Nico: Okay.

0:33:07.760,0:33:08.640
David: Right?

0:33:08.640,0:33:09.520
Nico: Yeah. Let's do that.

0:33:09.520,0:33:15.120
David: So imagine I want to create 
a commitment from hashing a value,

0:33:15.120,0:33:18.800
this is not super secure as is.

0:33:18.800,0:33:19.610
Nico: Okay.

0:33:19.610,0:33:21.600
David: Actually, let me ask you why.

0:33:21.600,0:33:23.560
Do you see why this is not the best commitment?

0:33:23.560,0:33:25.380
Nico: In terms of hiding?

0:33:25.380,0:33:27.600
David: In terms of hiding, yeah.

0:33:27.600,0:33:32.880
Nico: Well, I guess every time I commit to 
v, I'll always have the same commitment.

0:33:32.880,0:33:34.200
David: True.

0:33:34.200,0:33:36.080
Nico: I guess, somewhat deterministic, right?

0:33:36.080,0:33:37.200
David: Yeah. It's deterministic.

0:33:37.880,0:33:41.400
Yeah. If you have two commitments and 
you already know the commitment value,

0:33:41.400,0:33:42.720
you can distinguish them.

0:33:42.720,0:33:44.153
Nico: Yes. Makes sense.

0:33:44.153,0:33:46.560
David: Any other reason that you can think of?

0:33:46.560,0:33:47.466
Nico: I guess --

0:33:47.466,0:33:48.200
David: That's a good one.

0:33:48.200,0:33:55.440
Nico: If I know candidate values, maybe v1, v2, 
I can hash v1 and v2 to see which one you used.

0:33:55.440,0:33:56.560
David: Right.

0:33:56.560,0:33:58.920
So you can try values by yourself,

0:33:58.920,0:34:04.000
and if this is part of the values you can 
try, you can also see that it's not a --

0:34:04.000,0:34:06.000
you can discover the value behind it.

0:34:06.000,0:34:07.120
So basically you're right.

0:34:08.280,0:34:11.240
With these examples, we can 
clearly see that it's not hiding.

0:34:12.840,0:34:14.000
And you can think of other things,

0:34:14.000,0:34:17.572
like if v is pretty small, you can 
try all the values from zero --

0:34:17.572,0:34:22.160
Nico: Brute force it?
David: From zero to one and stuff like that.

0:34:22.160,0:34:24.280
So how do we fix that?

0:34:24.280,0:34:30.991
Basically what we can do is that we 
can append some randomness. And I --

0:34:30.991,0:34:33.200
Nico: Is this r the same as that r?

0:34:33.200,0:34:35.120
I'm guessing, no, right?

0:34:35.120,0:34:35.720
David: Yeah.

0:34:35.720,0:34:37.001
Nico: Yeah. Yeah. Let's remove this now.

0:34:37.001,0:34:38.182
David: Let's remove that.

0:34:38.182,0:34:38.193
Nico: Cool.

0:34:38.193,0:34:42.780
David: So by appending some randomness to 
the hash, then you make it impossible to --

0:34:42.780,0:34:47.040
I guess, to compute the hash and see if it checks,

0:34:47.040,0:34:48.440
because you don't know what that randomness is.

0:34:48.440,0:34:51.752
And if that randomness is large enough, then --

0:34:51.752,0:34:52.780
Nico: I can't brute force it, right?

0:34:52.780,0:34:54.160
David: You cannot brute force it.

0:34:54.160,0:34:56.200
Exactly.

0:34:56.840,0:34:57.650
There's other --

0:34:57.650,0:34:59.560
Nico: So now, if I commit to v multiple times,

0:34:59.560,0:35:03.760
I'll have different randomness and the 
commitment will be different every time, right?

0:35:03.760,0:35:05.400
David: Exactly, also.

0:35:05.400,0:35:13.000
So every time you commit, you sample r randomly 
and so you get random different commitments.

0:35:13.000,0:35:15.520
And so here, if you imagine that 
you are using a hash function,

0:35:15.520,0:35:18.180
then this is one way of really hiding it.

0:35:18.180,0:35:19.040
Nico: That makes sense.

0:35:19.040,0:35:21.440
David: And this will --

0:35:21.440,0:35:26.920
We can also talk about the distribution, 
but since r is randomly distributed,

0:35:26.920,0:35:31.821
then the commitment is also uniformly 
distributed across the space.

0:35:31.821,0:35:33.480
Nico: Makes sense. And now our
simulator is going to be happy.

0:35:33.480,0:35:34.400
David: Exactly.

0:35:34.400,0:35:35.320
Very easy to simulate.

0:35:35.320,0:35:39.040
You just pick random values and that's fine.

0:35:39.040,0:35:43.960
Nico: So you showed us also this commitment 
from the Schnorr protocol with g to some power.

0:35:43.960,0:35:46.760
How would we randomize it in that case?

0:35:46.760,0:35:48.560
David: Yeah. g to the power x.

0:35:48.560,0:35:55.560
Actually, maybe it's something that I didn't 
mention previously, but in our simulator,

0:35:55.560,0:36:01.240
we really want things to look like the 
same distribution as a real prover.

0:36:01.800,0:36:08.160
So here, if the real prover is doing things that 
are really uniformly distributed on the domain,

0:36:08.160,0:36:10.160
then it's easier to create a simulator

0:36:10.160,0:36:15.480
because you can just pick things that are 
uniformly distributed on the same domain.

0:36:15.480,0:36:19.160
And so people won't be able to distinguish them.

0:36:19.160,0:36:23.240
But if this is distributed over like some values

0:36:23.240,0:36:27.560
and the simulator can pick 
different values, different sets,

0:36:28.080,0:36:33.440
then these sets are different and then it's easier 
for the distinguisher to differentiate them.

0:36:33.440,0:36:35.080
So that's something that's --

0:36:35.080,0:36:38.400
when you create a simulator, that's something 
you have to keep in mind all the time.

0:36:38.400,0:36:45.320
You have to do something that's exactly the 
same set as a real prover in perfect ZK,

0:36:45.320,0:36:50.200
or almost the same set in 
statistical ZK or computational ZK.

0:36:50.200,0:36:54.000
And so the insight here is that it's 
easier to do that if it's purely random,

0:36:54.000,0:36:54.980
if it looks purely random.

0:36:54.980,0:36:56.600
Nico: That makes sense.

0:36:56.600,0:37:00.440
David: Which is in our case with 
the hash, but not here, right?

0:37:00.440,0:37:01.560
Nico: Yes.

0:37:01.560,0:37:06.680
David: So Pedersen commitments are already here.

0:37:06.680,0:37:10.000
I never know how to write it, but 
I think this is how you write it.

0:37:10.000,0:37:10.464
Nico: That's correct.

0:37:10.464,0:37:14.760
David: Pedersen commitments 
are basically very simple.

0:37:14.760,0:37:17.520
You just multiply this with another base,

0:37:17.520,0:37:21.800
which you don't know the discrete 
log of, raised to the power r.

0:37:21.800,0:37:22.620
This is your randomness.

0:37:22.620,0:37:23.760
Nico: Again. Okay.

0:37:23.760,0:37:29.600
David: And so here, basically, this 
will give you any points in your group,

0:37:29.600,0:37:33.880
and so we're back to like a very good hiding.

0:37:33.880,0:37:38.040
Nico: Something that looks random. Okay.

0:37:38.040,0:37:43.600
David: In the case of KZG, you have 
something very similar to that,

0:37:45.240,0:37:49.400
except that people don't really 
use it because of the costs.

0:37:49.400,0:37:58.040
And so we don't have this perfect hiding and 
so we have to do some other randomization.

0:37:58.040,0:38:01.800
Nico: So we'll get probably 
something computationally hiding?

0:38:01.800,0:38:02.880
David: No.

0:38:02.880,0:38:03.513
Nico: No. Okay.

0:38:03.513,0:38:06.741
David: Because we'll actually 
randomize things in a good way.

0:38:06.741,0:38:09.340
Nico: Okay. That's great.
David: So we're still in the perfect hiding.

0:38:09.340,0:38:11.457
Nico: Okay. So we've now --

0:38:11.457,0:38:11.467
David: [?]

0:38:11.467,0:38:16.600
Nico: We now have a method to 
hide our PLONK commitments.

0:38:16.600,0:38:18.220
How do we deal with the evaluations?

0:38:18.220,0:38:21.240
David: Okay. So --

0:38:21.240,0:38:23.680
So these commitments are not commitments of values

0:38:23.680,0:38:25.760
where we're talking about polynomials.

0:38:26.360,0:38:37.000
And so you have to think of polynomials are 
like a polynomial f of a degree d, right?

0:38:37.000,0:38:38.520
This is what we're talking about.

0:38:38.520,0:38:39.320
Nico: Yeah.

0:38:39.320,0:38:42.840
David: And so if you start giving --

0:38:42.840,0:38:46.520
If I start giving you evaluations 
of that polynomial of degree d,

0:38:46.520,0:38:49.200
I'm starting to leak information 
about that polynomial.

0:38:52.520,0:38:54.320
Actually, let me ask you a question.

0:38:54.320,0:38:58.863
How many evaluations do you need to 
recover my polynomial f of a degree d?

0:38:58.863,0:38:59.630
Nico: That would be d + 1.

0:38:59.630,0:39:00.720
David: d + 1, right?

0:39:00.720,0:39:03.560
By definition, if you have d + 1 evaluations,

0:39:04.560,0:39:06.460
you know exactly the 
description of the polynomial.

0:39:06.460,0:39:06.880
Nico: Yeah.

0:39:06.880,0:39:08.480
David: That's good enough.

0:39:08.480,0:39:14.440
So obviously we don't want to have d + 
1 evaluation for the same polynomial,

0:39:14.440,0:39:17.680
otherwise we're screwed.

0:39:17.680,0:39:22.560
But even one evaluation is bad 
enough, because this might --

0:39:22.560,0:39:27.520
this evaluation is really tied to 
the polynomial and to the witness.

0:39:27.520,0:39:30.960
And so this might give some 
advantage to our adversary.

0:39:30.960,0:39:32.714
They might be able to distinguish --

0:39:32.714,0:39:36.000
Nico: Well, now they only need to find 
d values because they already got 1,

0:39:36.000,0:39:39.107
if they're trying to collect d + 1.

0:39:39.107,0:39:40.260
David: Well, we --
Nico: I'm guessing we've given 1 to them.

0:39:40.260,0:39:45.020
David: Yeah. But they won't be able to get 
d + 1, but maybe one is enough to distinguish.

0:39:45.020,0:39:45.700
Nico: I see.

0:39:45.700,0:39:48.545
David: Because they just have to distinguish, 
right? They don't have to recover f.

0:39:48.545,0:39:48.880
Nico: We're in this game.

0:39:48.880,0:39:50.640
David: They just have to play that game, right?

0:39:54.000,0:39:59.180
So the way we do things is that 
we randomize these polynomials.

0:39:59.180,0:40:00.380
Nico: What does that mean?

0:40:00.380,0:40:01.800
David: So what does that mean?

0:40:01.800,0:40:03.120
We basically want --

0:40:03.120,0:40:07.920
because if we randomize the polynomial, then 
we don't have the same polynomial, right?

0:40:07.920,0:40:12.520
And if we add randomness in the polynomial, 
and so it kind of messes the protocol,

0:40:12.520,0:40:15.720
and then the verifier doesn't have 
something they can actually check.

0:40:15.720,0:40:18.360
So this randomization has to be controlled.

0:40:18.360,0:40:24.640
It has to preserve the rules of the games and 
the identities that we want to do in PLONK.

0:40:24.640,0:40:28.280
And so it's, I don't know, 
a controlled randomization.

0:40:28.280,0:40:29.600
Nico: Okay.

0:40:29.600,0:40:33.760
David: I don't know how much I need to recap here,

0:40:33.760,0:40:37.760
but in PLONK you have these vanishing polynomials,

0:40:37.760,0:40:44.360
and we do stuff on a domain, the circuit 
domain, where we chose a bunch of points.

0:40:44.360,0:40:46.160
Nico: So actually, maybe we can write this down.

0:40:46.160,0:40:49.800
We have our roots of unity. I think 
those were covered in previous sessions.

0:40:49.800,0:40:50.560
David: Okay.

0:40:52.080,0:40:54.480
So let's say we have a domain H,

0:40:54.480,0:41:03.394
which is the domain generated by, let's 
say, g, our generator, or -- yeah, or the --

0:41:03.394,0:41:05.273
Nico: I think they've been using 
Omega in the previous sessions.

0:41:05.273,0:41:06.791
David: Omega? All right. Let's use that.

0:41:06.791,0:41:08.240
Nico: If that'll be helpful.

0:41:08.240,0:41:11.800
David: And we also --

0:41:11.800,0:41:19.520
So you must have seen a vanishing polynomial, 
which you can write in a succinct way.

0:41:20.360,0:41:23.920
Maybe I'll write the size of H here, minus one.

0:41:24.720,0:41:31.360
And all the roots of unity, or the Omega 
roots of unity will basically cancel

0:41:31.360,0:41:37.000
when raised to the power the size of 
their domain, the order of their group.

0:41:37.000,0:41:41.880
And so we have a nice succinct 
description of our polynomial,

0:41:41.880,0:41:43.440
our vanishing polynomial.

0:41:43.440,0:41:44.400
Nico: Okay.

0:41:44.400,0:41:48.400
David: If that doesn't make sense, I guess 
people can just go back to previous videos.

0:41:48.400,0:41:49.090
Nico: Cool.

0:41:49.090,0:41:51.120
David: So the way our f works.

0:41:51.120,0:42:00.840
So imagine that there's some polynomial in 
our PLONK or STARK, or whatever, which is f.

0:42:00.840,0:42:04.720
And we want to create some 
f prime which is randomized.

0:42:04.720,0:42:10.897
What we're going to do is that f 
prime is going to be equal to f --

0:42:10.897,0:42:10.913
Nico: As before.

0:42:10.913,0:42:24.631
David: As before, plus our vanishing polynomial 
times, let's call it g, times g of x.

0:42:24.631,0:42:27.120
Nico: Do you want maybe a different 
letter to avoid conflict here?

0:42:27.120,0:42:30.040
David: Oh. Damn it. m.

0:42:30.040,0:42:30.960
Nico: Yeah, m --

0:42:30.960,0:42:33.280
David: Let's do m of x. All right.

0:42:33.280,0:42:35.920
So when we're looking at that,

0:42:35.920,0:42:43.180
we still have that f prime of x is 
equal to f of x when we're in our domain.

0:42:43.180,0:42:46.230
Nico: So when we're evaluating at these Omegas.

0:42:46.230,0:42:49.627
David: At these Omega or powers of Omegas, right?

0:42:49.627,0:42:50.153
Nico: I see. Because --

0:42:50.153,0:42:52.660
David: Because this thing here will be zero.

0:42:52.660,0:42:53.360
Nico: Right?

0:42:53.360,0:42:58.834
David: Right? Whenever we have x is equal 
to a power of Omega, that right side --

0:42:58.834,0:42:59.400
Nico: Disappears.

0:42:59.400,0:43:00.240
David: Disappears.

0:43:00.240,0:43:01.360
Nico: Cool.

0:43:01.360,0:43:06.400
David: But when we're not, and 
usually when we have evaluations here,

0:43:06.400,0:43:09.520
we evaluate these polynomials at 
points that are outside of our domain.

0:43:09.520,0:43:10.160
Nico: Right.

0:43:10.160,0:43:14.440
David: Not necessarily, but with high 
probability, high probability enough,

0:43:14.440,0:43:15.960
because our domain is pretty small.

0:43:17.720,0:43:22.320
Then this thing will activate and 
will randomize our evaluations.

0:43:22.320,0:43:24.080
Nico: So what is m in this case?

0:43:24.080,0:43:29.120
David: So m, in this case, is a random polynomial,

0:43:29.120,0:43:41.040
you know m(x) = r₀ + r₁X + r₂X²,
and so on.

0:43:42.000,0:43:50.360
And the number of random values here, or 
the degree of that random polynomial m,

0:43:50.360,0:43:52.760
is dictated by the number of evaluations.

0:43:52.760,0:43:57.040
So, the more evaluations, the 
more randomness you want to have.

0:43:57.040,0:44:00.160
Nico: I see.
David: And there's a --

0:44:00.760,0:44:04.600
I guess there is different 
ways to prove that this works.

0:44:05.800,0:44:10.720
Maybe a way to prove that this works is 
that if you evaluate this in, let's say,

0:44:10.720,0:44:16.480
if you evaluate f prime in two 
points, you can see that you can --

0:44:16.480,0:44:24.480
so, we have f prime of I don't know, 
alpha₁ and f prime of alpha₂.

0:44:24.480,0:44:30.080
If you evaluate that at two 
points, then you can see that --

0:44:30.960,0:44:35.560
If you evaluate that at two points, then 
you can see that you can basically --

0:44:35.560,0:44:41.000
and you give them whatever values you 
want, you can see that you can recover --

0:44:41.000,0:44:43.360
you have a system of equations, basically.

0:44:44.760,0:44:48.720
If you have enough random 
values, so let's say two.

0:44:49.400,0:44:56.800
You have two unknowns in a system of 
equations of linearly independent equations --

0:44:56.800,0:44:58.560
Of two linearly independent equations.

0:44:58.560,0:45:00.040
And so, you can solve it.

0:45:00.040,0:45:00.730
Nico: Right.

0:45:00.730,0:45:02.400
David: I don't know if that made sense,

0:45:02.400,0:45:05.680
but that's one way you can try 
to think about it, basically.

0:45:05.680,0:45:07.120
I'll rephrase that in a different way,

0:45:07.120,0:45:13.800
but you can obtain any evaluations you 
want for two points if you have two --

0:45:13.800,0:45:16.120
if you have a degree 1 polynomial,

0:45:16.120,0:45:20.120
if you have two randomness coefficients.

0:45:20.120,0:45:23.000
And so if you have more evaluations, 
you want more randomness coefficients.

0:45:23.000,0:45:28.880
Nico: So I guess the last question I had is, what 
is the total degree of this f prime polynomial?

0:45:28.880,0:45:29.560
David: All right.

0:45:29.560,0:45:36.040
So because we're adding stuff here, unfortunately, 
we're raising the degree of this thing.

0:45:37.040,0:45:47.640
And so it's going to be basically f most likely 
is already the degree of the vanishing polynomial.

0:45:49.120,0:45:52.680
Just because of PLONK or 
whatever we're doing for -- for reasons.

0:45:52.680,0:45:53.680
Nico: Sure.

0:45:53.680,0:46:00.520
David: But m here is the 
number of evaluation minus one.

0:46:00.520,0:46:01.600
Nico: Minus one.

0:46:01.600,0:46:02.240
David: Right.

0:46:02.240,0:46:07.480
Because if you do two evaluations, 
you have a degree 1 polynomial.

0:46:07.480,0:46:09.520
And so you're going to --

0:46:09.520,0:46:14.080
Basically, you're multiplying 
that, and so if this is degree n,

0:46:14.080,0:46:17.880
then you get n + 2, if 
you have two evaluations.

0:46:17.880,0:46:28.200
And so you're increasing the -- you have a,
d + 2 maybe, or d + 3, or something like that.

0:46:28.200,0:46:31.480
So you're adding some degrees, 
which can be annoying.

0:46:31.480,0:46:32.080
Nico: Right.

0:46:32.080,0:46:34.760
Because it's a cost to the prover, the verifier.

0:46:34.760,0:46:37.140
David: Yeah. Yeah, basically.

0:46:37.140,0:46:39.460
Nico: Cool. Shall we look at KZG?

0:46:39.460,0:46:40.640
David: Oh, yeah.

0:46:40.640,0:46:44.240
So we talked about hash, I guess, in Pedersen,

0:46:44.240,0:46:47.320
let's briefly mention KZG.

0:46:48.160,0:46:52.080
So KZG has a different way to do commitments.

0:46:52.080,0:46:54.188
I guess, you've talked about 
that in previous sessions.

0:46:54.188,0:46:54.920
Nico: Yeah. Session 1, absolutely.

0:46:54.920,0:46:59.520
David: So commitments of a function is basically

0:46:59.520,0:47:02.480
the commitment of that 
function at some secret points.

0:47:02.480,0:47:06.360
Should I -- maybe a Tau, I guess.

0:47:07.960,0:47:11.080
And so you're not really --

0:47:11.080,0:47:14.680
You're revealing something, especially 
against an adversary that's unbounded.

0:47:14.680,0:47:15.753
Nico: Right. That makes sense.

0:47:15.753,0:47:19.800
David: When you're trying to do these 
proofs, you're revealing the discrete log.

0:47:19.800,0:47:23.840
So the adversary can just see 
that if they're unbounded.

0:47:23.840,0:47:27.007
Nico: So we revealed one of the evaluations of f.

0:47:27.007,0:47:30.120
David: Right. So what's the 
natural way of hiding that?

0:47:30.120,0:47:31.640
Nico: Like we just did earlier.

0:47:31.640,0:47:32.200
David: Exactly.

0:47:32.200,0:47:33.880
Nico: Adding more.

0:47:33.880,0:47:38.960
David: You just add more randomness 
in this masking polynomial.

0:47:38.960,0:47:41.360
So nothing magical.

0:47:41.360,0:47:43.280
Yeah. You see that as an evaluation.

0:47:43.280,0:47:44.360
Nico: Cool.

0:47:44.360,0:47:46.240
David: So maybe it's worth mentioning,

0:47:46.240,0:47:51.320
but PLONK is instantiated with 
KZG or different commitments.

0:47:51.320,0:47:53.600
Mina uses Pedersen commitments.

0:47:53.600,0:47:55.320
And so depending on the commitment you're using,

0:47:55.320,0:47:58.240
you have different hiding polynomials. 
But you have different degrees.

0:47:58.240,0:48:01.800
Nico: That makes sense. I had 
another question, which is,

0:48:01.800,0:48:05.040
when we're working with KZG, 
we have this trusted setup.

0:48:06.520,0:48:11.040
Where does the trusted setup happen 
in this game, and does it matter?

0:48:11.040,0:48:13.080
David: Because we're still --

0:48:13.080,0:48:17.520
As I said, we still want to create these 
proofs with a simulator to prove ZK,

0:48:17.520,0:48:22.600
we still care about perfect or statistical 
or computational ZK and all these things.

0:48:22.600,0:48:24.200
So this is basically the same.

0:48:24.200,0:48:26.240
Like we're still in that model,

0:48:26.240,0:48:31.040
except that we have one more step where 
we have to create the trusted setup.

0:48:31.040,0:48:34.080
That Tau here for KZG.

0:48:35.480,0:48:37.120
And so where does it go?

0:48:37.120,0:48:47.160
Basically, the simulator here will create the 
CRS or SRS, let's call it SRS, structured,

0:48:48.120,0:48:51.880
and we'll output that trapdoor.

0:48:53.200,0:48:54.640
I'm going to kind of abuse notation.

0:48:54.640,0:48:57.240
Usually you want to do something 
like you want to choose that b first.

0:48:57.240,0:49:01.320
And if you're in the prover, 
you have a normal SRS.

0:49:01.320,0:49:04.480
If you're in the simulator setting,

0:49:04.480,0:49:08.080
then the simulator can create the 
SRS, which might be different.

0:49:08.080,0:49:12.880
So the distinguisher here might be able 
to tell that the SRS looks different also.

0:49:12.880,0:49:14.760
So that's something that's possible.

0:49:14.760,0:49:21.668
So I'm abusing things, but just keep in mind 
that the SRS might be different here. And --

0:49:21.668,0:49:22.640
Nico: Quick question!
What is this?

0:49:22.640,0:49:24.200
Is this our toxic waste?

0:49:24.200,0:49:24.800
David: Oh, yeah.

0:49:24.800,0:49:26.000
That's the toxic waste.

0:49:26.000,0:49:27.240
That's the trapdoor.

0:49:27.240,0:49:29.628
That's the secret point.

0:49:29.628,0:49:30.240
Nico: Okay. Cool.

0:49:30.240,0:49:38.280
David: So now the simulator has some extra 
power, they can use the knowledge of the Tau.

0:49:38.280,0:49:41.800
Nico: Interesting. So it 
would come in here as well?

0:49:41.800,0:49:42.900
David: Exactly.

0:49:42.900,0:49:43.560
Nico: Cool.

0:49:43.560,0:49:46.040
David: So we would add Tau here.

0:49:46.040,0:49:50.880
And actually, if you look at the ZK 
proof for PLONK and stuff like that,

0:49:50.880,0:49:53.360
they don't really care about 
choosing the challenges,

0:49:54.400,0:49:57.600
because they have so much power already 
that they can just use the trapdoor.

0:49:57.600,0:50:01.920
Nico: That makes sense. Okay. 
And so here the order of things,

0:50:01.920,0:50:08.120
is it always the case that the adversary chooses 
the instance and witness after the SRS exists?

0:50:08.120,0:50:08.600
David: Right.

0:50:08.600,0:50:14.680
Okay. So maybe we can mention that, but there 
is an adaptive and non-adaptive version.

0:50:14.680,0:50:17.225
We have so many flavors of ZK --

0:50:17.225,0:50:17.480
Nico: Okay. Of course.

0:50:17.480,0:50:23.080
David: But here the simulator has 
a chance to choose the SRS before,

0:50:23.800,0:50:26.320
or has a chance -- doesn't 
have a chance, let's say,

0:50:26.320,0:50:28.560
before seeing the witness and instance.

0:50:28.560,0:50:34.081
So this is called the adaptive model 
because the adversary can see the SRS.

0:50:34.081,0:50:35.940
Nico: And can adapt to that SRS.
David: And can adapt to that.

0:50:35.940,0:50:36.660
Nico: That kind of makes sense.

0:50:36.660,0:50:41.640
David: But if this came before, then we 
would say it's the non-adaptive model

0:50:41.640,0:50:45.959
because the adversary is stuck 
with a witness and an instance --

0:50:45.959,0:50:49.200
Nico: And cannot adapt to the SRS.
David: And then the simulator can see that --

0:50:49.200,0:50:53.320
So the simulator would see -- 
oh, sorry, not the witness.

0:50:53.320,0:50:53.980
Nico: Right.

0:50:53.980,0:50:59.880
David: The simulator would see the 
instance in that non-adaptive model.

0:50:59.880,0:51:02.480
Nico: Correct. Yeah. Cool.

0:51:02.480,0:51:04.960
David: But it doesn't matter too much.

0:51:05.760,0:51:12.400
What we want to keep in mind is that 
we want to give the least amount of --

0:51:12.400,0:51:17.440
or the more power the distinguisher 
has, the better, generally.

0:51:17.440,0:51:22.000
Nico: So as a sort of recap of the properties,

0:51:22.000,0:51:24.240
we said it's okay to have 
computational zero knowledge

0:51:24.240,0:51:29.120
because our adversaries are going to be bounded.

0:51:29.120,0:51:33.880
Adaptive, we want for sure because 
our trusted setup already exists.

0:51:33.880,0:51:38.600
David: Or it's more like you want to 
give that kind of power to your --

0:51:39.560,0:51:42.040
it's a better proof if the 
adversary has more power.

0:51:42.040,0:51:43.200
Nico: That makes sense.

0:51:43.200,0:51:46.240
David: But I'm not saying -- and 
also for computational, it's okay,

0:51:46.240,0:51:48.850
but usually perfect is better.

0:51:48.850,0:51:48.873
Nico: Right. Of course.

0:51:48.873,0:51:51.434
David: Or statistical is 
better. Like these two are --

0:51:51.434,0:51:56.880
Nico: What I was trying to get to is 
what do our protocols have in practice?

0:51:56.880,0:52:03.640
So if I do hide my PLONK commitments and I 
do have these maskings for my evaluations,

0:52:04.320,0:52:06.240
what flavor of zero knowledge do we get?

0:52:06.240,0:52:09.840
David: So usually what you get is statistical ZK.

0:52:09.840,0:52:10.400
Nico: Cool.

0:52:10.400,0:52:14.520
And to my understanding, it's mostly about --

0:52:14.520,0:52:19.520
it's not perfect because you have some 
points that won't work in a transcript.

0:52:20.459,0:52:23.920
Like for example, if the evaluation 
points are in your domain,

0:52:23.920,0:52:25.680
domain of the thing, things don't really work.

0:52:25.680,0:52:28.460
Like there's some edge cases where 
things don't work, but it's negligible.

0:52:28.460,0:52:30.405
And that's why we're in statistical.

0:52:30.405,0:52:31.837
Nico: That makes sense.

0:52:32.273,0:52:37.040
David: But it turns out that there 
was a recent result on PLONK and ZK,

0:52:37.040,0:52:43.640
zero knowledge-ness of PLONK and that 
it was actually not statistical ZK.

0:52:43.640,0:52:45.720
Maybe it was computational ZK, we don't know

0:52:45.720,0:52:46.220
Nico: Okay.

0:52:46.240,0:52:48.000
David: But it was proven not to be statistical ZK.

0:52:48.000,0:52:49.480
It was a small fix.

0:52:50.320,0:52:52.760
I think it was found maybe years ago,

0:52:52.760,0:52:56.440
but it was only published recently and 
it was fixed in the original paper.

0:52:57.200,0:53:00.320
Nico: So it is fixed. So the original paper --

0:53:00.320,0:53:04.660
Well, the fixed version of the paper is now 
back to being statistical zero knowledge.

0:53:04.660,0:53:05.080
David: Yeah.

0:53:05.080,0:53:08.200
So now we have statistical ZK PLONK.

0:53:09.040,0:53:14.480
Maybe worth mentioning also, about PLONK 
like basically all the papers come out.

0:53:14.480,0:53:18.480
Actually PLONK was doing better 
because they explain how to do ZK.

0:53:18.480,0:53:20.620
A lot of paper don't even 
explain to you how to do ZK.

0:53:20.620,0:53:23.540
They just exercise left for the reader.

0:53:23.540,0:53:26.440
Nico: Okay. Write your simulator yourself.

0:53:26.440,0:53:27.560
David: Yeah.

0:53:27.560,0:53:28.720
To do that proof yourself.

0:53:28.720,0:53:29.880
But not even simulator, right?

0:53:29.880,0:53:32.241
It's like how do I even add ZK in my scheme.

0:53:32.241,0:53:33.170
Nico: Right.

0:53:33.170,0:53:37.142
David: At least PLONK told you how to 
add ZK. They just didn't have a proof.

0:53:37.142,0:53:44.620
And so that was the prime. There was no 
proof, or at least it was not statistical ZK.

0:53:44.620,0:53:46.000
Nico: That makes sense.

0:53:46.000,0:53:51.480
David: And I can talk a bit about that as a --

0:53:51.480,0:53:52.680
It's kind of hard to --

0:53:52.680,0:53:54.880
Okay. Let me make some space.

0:53:54.880,0:54:00.160
It's kind of hard to explain on a whiteboard 
here, especially as PLONK is complicated.

0:54:00.160,0:54:03.228
But maybe I can talk about some of 
the intuition behind the attack.

0:54:03.228,0:54:05.160
Nico: Yeah. That sounds perfect.

0:54:05.160,0:54:08.880
David: The intuition is, of course, that --

0:54:08.880,0:54:10.640
So we don't want to write a simulator.

0:54:10.640,0:54:14.200
If we could write a simulator, then 
we would have a proof that it's ZK.

0:54:17.200,0:54:19.600
So what we want is to write an adversary,

0:54:19.600,0:54:26.400
but I'm going to write a different 
kind of adversary because --

0:54:26.400,0:54:30.160
So what they did was not to 
prove that it was not ZK.

0:54:30.160,0:54:35.560
What they did was to prove that it 
was not "witness indistinguishable".

0:54:35.560,0:54:39.480
And that's a different 
property, a weaker property.

0:54:39.480,0:54:42.640
And so if you don't have that, you don't have ZK.

0:54:42.640,0:54:45.080
If you have ZK, you have that. If you 
don't have that, you don't have ZK.

0:54:45.080,0:54:47.320
Nico: Makes sense.

0:54:47.320,0:54:53.960
David: Informally, witness 
indistinguishability is -- you have two witnesses.

0:54:53.960,0:54:56.320
So the adversary or the 
verifier creates two witnesses,

0:54:57.600,0:55:00.370
and then they give that to the 
prover. So you're the prover.

0:55:00.370,0:55:00.720
Nico: Sure.

0:55:00.720,0:55:03.520
David: And then you choose at 
random or like however you want,

0:55:03.520,0:55:06.600
at random, most likely which 
witness you want to prove.

0:55:07.600,0:55:09.000
You give it back to me.

0:55:09.000,0:55:15.720
If I can guess which witness of the two witness 
I gave you, you proved, then you don't have this.

0:55:17.240,0:55:22.760
So they demonstrate an attack for 
a very simple circuit for that.

0:55:22.760,0:55:30.480
And basically the problem in PLONK is 
that you have this quotient polynomial T,

0:55:31.480,0:55:39.800
which was masked, actually was fine, 
but they actually chunked it in T₁.

0:55:39.800,0:55:41.820
Nico: T low, T mid and T high, right?

0:55:41.820,0:55:42.460
David: Yeah, exactly.

0:55:42.460,0:55:46.720
I'll write it like that. So T(x) was 
actually chunked because it was too big.

0:55:47.320,0:55:59.020
So you had
T low + Xⁿ . T mid + X²ⁿ . T high, was it?

0:55:59.020,0:56:01.120
Nico: Yeah. I think so.

0:56:01.120,0:56:09.040
David: And because they split it like this, 
and they forgot to mask these polynomials,

0:56:09.040,0:56:12.860
these three polynomials, 
then you had some leakage.

0:56:12.860,0:56:15.440
Nico: Right. Because these get 
committed individually, right?

0:56:15.440,0:56:15.830
David: Exactly.

0:56:15.830,0:56:19.680
Nico: And then we're back to 
this problem here up there.

0:56:19.680,0:56:21.160
David: And then we're back to this problem.

0:56:21.160,0:56:27.920
And so if I remember correctly, if you 
write the equations with their example of --

0:56:27.920,0:56:33.160
there's like one gate and identical permutations,

0:56:33.160,0:56:37.280
it was a very simple example, 
but they say it generalizes.

0:56:37.280,0:56:41.680
And basically you could see a 
relation between T low and T mid.

0:56:41.680,0:56:45.360
There was some sort of relation when 
you would analyze the transcripts.

0:56:45.360,0:56:50.840
If you could see that relation based on 
the first witness or the second witness,

0:56:50.840,0:56:53.200
you could distinguish them.

0:56:53.200,0:56:56.280
And so the easy fix was just to mask them as we --

0:56:56.280,0:56:56.820
Nico: As we did.

0:56:56.820,0:56:57.660
David: As we saw --

0:56:57.660,0:56:58.640
Nico: Right down there.

0:56:58.640,0:56:59.154
David: Previously.

0:56:59.154,0:56:59.177
Nico: Cool.
David: Yeah.

0:56:59.177,0:57:01.080
Nico: Very good.
David: Cool. Yeah.

0:57:02.480,0:57:05.960
Nico: Does that wrap it up?

0:57:05.960,0:57:06.520
David: Yeah.

0:57:06.520,0:57:08.914
I think if you have any other 
questions, I'm happy to answer.

0:57:08.914,0:57:11.480
Nico: Maybe a quick summary of everything we saw.

0:57:11.480,0:57:12.200
David: Yeah.

0:57:12.200,0:57:15.680
So ZK is important or not, 
depending on the scheme.

0:57:15.680,0:57:18.040
Sometimes you only care about succinctness.

0:57:18.040,0:57:20.040
There's different flavors of ZK.

0:57:20.040,0:57:23.880
We like the perfect flavor, but we have 
perfect, statistical and computational.

0:57:23.880,0:57:27.000
And these are fine, depending on context.

0:57:27.000,0:57:33.720
And as we saw, statistical is usually 
what we get with PLONK and other schemes.

0:57:33.720,0:57:37.920
We talked about dishonest 
verifier, honest verifier

0:57:37.920,0:57:41.400
and that dishonest verifier, 
it's fine if we don't get it

0:57:41.400,0:57:47.160
because usually we are in the non-interactive 
setting with the Fiat–Shamir transformation.

0:57:47.160,0:57:53.920
And we also talked about 
adaptive and non-adaptive models

0:57:53.920,0:58:00.560
and we prefer for in the adaptive 
model and these kind of things.

0:58:00.560,0:58:06.040
And I guess we talked about these two things 
here, the simulator and how to hide things.

0:58:06.720,0:58:09.280
So simulator is the way we create proofs

0:58:09.280,0:58:13.880
and the simulator has different 
powers depending on all these models.

0:58:13.880,0:58:16.080
Maybe they can query the verifier

0:58:16.080,0:58:22.080
and they don't really need to because they 
know what the verifier is going to do,

0:58:22.080,0:58:27.760
or they need to and they need to guess in 
the honest or dishonest verifier settings.

0:58:27.760,0:58:29.920
And we also saw hiding commitments.

0:58:29.920,0:58:35.520
So in KZG or Pedersen or hashes, how 
can we really make it look random

0:58:35.520,0:58:42.160
or distributed randomly even in 
spite of evaluations as well?

0:58:42.160,0:58:48.400
So how do we make it so that these evaluations 
look random and don't leak anything?

0:58:48.400,0:58:52.474
And I guess finally we saw how PLONK 
was not statistically zero knowledge --

0:58:52.474,0:58:53.320
Nico: And that was fixed.

0:58:53.320,0:58:53.880
David: Yeah.

0:58:53.880,0:58:56.040
Because they forgot to mask these polynomials.

0:58:56.040,0:58:59.800
Nico: One thing I really want to add 
is this point to me is very important

0:58:59.800,0:59:05.600
and I've seen this mistake made many times where 
people think hashing something makes it private.

0:59:05.600,0:59:10.200
And that's not true because that 
is now a deterministic commitment.

0:59:10.200,0:59:14.240
And so you get this sort 
of fingerprint of the data.

0:59:14.240,0:59:20.920
So, I wish people pay attention 
to this and remember that.

0:59:20.920,0:59:21.400
Great.

0:59:21.400,0:59:26.040
I think now people can say they are experts in 
zero knowledge rather than just ZK the acronym.

0:59:27.640,0:59:28.880
Thanks for clearing that up.

0:59:28.880,0:59:29.400
David: Cool.

0:59:29.400,0:59:41.600
Thanks for having me.
