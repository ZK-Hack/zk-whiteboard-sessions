0:00:07.000,0:00:10.000
S2 Module 2: The Sum-Check Protocol with Justin Thaler

0:00:10.716,0:00:12.680
Justin: Hi, I'm Justin Thaler.

0:00:12.680,0:00:16.920
I'm an associate professor at Georgetown 
and a research partner at a16z.

0:00:16.920,0:00:18.920
Going to talk about the Sum-Check Protocol today.

0:00:18.920,0:00:20.080
Tracy: Cool.

0:00:20.080,0:00:20.680
I'm Tracy.

0:00:20.680,0:00:22.000
I'm co-founder of Pluto.

0:00:22.000,0:00:24.850
I've been working with zk-SNARKs for app devs.

0:00:24.850,0:00:29.720
Justin: All right. So the topic 
today is the Sum-Check Protocol,

0:00:30.440,0:00:35.440
which is due to Lund, Fortnow, 
Karloff, and Nisan from way back

0:00:35.440,0:00:40.720
in the very early days of 
Verifiable Computing, 1990 or so.

0:00:40.720,0:00:43.360
Now, this solves the following problem,

0:00:43.360,0:00:47.040
which probably looks a little 
funny the first time you see it.

0:00:47.600,0:00:54.760
But the goal is to compute a 
big sum of the following form.

0:00:54.760,0:00:58.760
So we're summing over n-bit inputs,

0:00:58.760,0:01:10.560
so x in {0,1}ⁿ of g(x), 
where g is some n-variate polynomial.

0:01:11.120,0:01:17.040
And the protocol is sort of going to be secure 
and efficient only if g is "low degree."

0:01:17.040,0:01:19.800
Let's not worry right now what low degree means.

0:01:20.760,0:01:28.000
And from the verifier's perspective, the 
Sum-Check Protocol is like a reduction.

0:01:28.000,0:01:31.680
This sum involves 2ⁿ terms. Right?

0:01:31.680,0:01:34.160
So the verifier could compute the sum on its own

0:01:34.160,0:01:37.480
by kind of evaluating g at 2ⁿ
points and summing it on its own.

0:01:37.480,0:01:40.640
The verifier is thinking, "oh, that's a lot 
of work. I don't want to do that myself."

0:01:40.640,0:01:44.040
"I want the prover, who I don't 
trust to do that work for me."

0:01:44.040,0:01:46.120
And so the verifier in the Sum-Check Protocol  

0:01:46.120,0:01:50.200
will ultimately only have to 
evaluate g at a single point.

0:01:50.200,0:01:55.040
But the wrinkle is that that 
single point is a random point,

0:01:55.040,0:01:57.680
and the randomness is not just from {0,1}.

0:01:57.680,0:02:01.680
It's from a much bigger space, 
something called a finite field.

0:02:01.680,0:02:03.840
So again, so for the verifier,

0:02:03.840,0:02:09.680
Sum-Check Protocol reduces this very difficult 
task of summing 2ⁿ evaluations of g,

0:02:09.680,0:02:12.480
to the task of just evaluating 
g at a single point.

0:02:12.480,0:02:14.680
Albeit, a point from kind 
of the whole field instead  

0:02:14.680,0:02:16.560
of the -- what we call the "Boolean hypercube".

0:02:16.560,0:02:17.708
Tracy: Cool.

0:02:17.708,0:02:19.200
Justin: Any questions?
Tracy: Makes sense. I think it's great.

0:02:19.200,0:02:19.880
Justin: All right.

0:02:19.880,0:02:25.840
So hopefully we'll see kind of 
why this protocol is so powerful,

0:02:26.480,0:02:32.440
why low degree polynomials sort of 
make sense to arise in proof systems.

0:02:32.440,0:02:34.280
And so we're going to kind 
of start at the beginning.

0:02:34.280,0:02:36.480
We're going to forget about the 
Sum-Check Protocol for a little bit

0:02:36.480,0:02:40.680
and just talk about polynomials for a few minutes.

0:02:40.680,0:02:41.800
Okay.

0:02:41.800,0:02:45.960
So we've already seen that the 
Sum-Check Protocol refers to

0:02:45.960,0:02:48.320
multivariate polynomials, n-variate polynomials.

0:02:48.320,0:02:52.360
But let me just go back to basics for a minute

0:02:52.360,0:02:55.520
and quickly talk about 
univariate polynomials. Right?

0:02:55.520,0:03:01.240
So a degree d univariate polynomial is just

0:03:01.240,0:03:09.760
a sum of coefficients times 
associated power of the one input.

0:03:09.760,0:03:15.040
So this is a degree d univariate 
polynomial that I just wrote.

0:03:15.040,0:03:17.860
Tracy: It's like the classic 
linear combination of terms.

0:03:17.860,0:03:18.800
Justin: Exactly.

0:03:18.800,0:03:21.600
And this is called the standard monomial basis.

0:03:21.600,0:03:24.800
These coefficients are 
coefficients of powers of x.

0:03:24.800,0:03:28.360
There are other bases that 
also make sense to think about,

0:03:28.920,0:03:31.320
as we'll see for the Sum-Check Protocol,

0:03:31.320,0:03:33.720
it's the "Lagrange basis" that makes more sense,

0:03:33.720,0:03:36.800
but kind of starting at with what 
people should be most comfortable with.

0:03:36.800,0:03:41.320
Univariate polynomial of degree d
in the standard monomial basis.

0:03:41.320,0:03:41.480
Okay.

0:03:41.480,0:03:45.640
And a basic fact, I always forget if this 
is the fundamental theorem of algebra

0:03:45.640,0:03:49.760
or something from kind of 8th grade or 9th grade,

0:03:49.760,0:03:58.880
but if p and q are two distinct,

0:03:58.880,0:04:07.000
so they're not the same degree 
(at most) d polynomials,

0:04:07.000,0:04:11.080
okay, then they have to 
disagree at almost all inputs.

0:04:11.080,0:04:20.480
So that means then p(x) = q(x)
for at most --

0:04:21.320,0:04:24.400
So a line -- two lines that are not 
the same, can agree at one point.

0:04:24.400,0:04:29.160
So d points. They can agree at d points.

0:04:30.920,0:04:31.240
Great.

0:04:31.240,0:04:35.040
So this is another way of saying this 
is just a reformulation of the fact that

0:04:35.040,0:04:39.320
any non zero degree d 
polynomial has at most d roots.

0:04:39.320,0:04:39.600
Right?

0:04:39.600,0:04:46.120
Because p(x) = q(x) is equivalent 
to like (p-q)(x) = 0.

0:04:46.120,0:04:49.000
So talking about agreement points 
of p and q is like the same as

0:04:49.000,0:04:50.680
talking about roots of p minus q.

0:04:50.680,0:04:51.520
Tracy: Right.

0:04:51.520,0:04:53.560
So if they share roots, they'll 
agree on all those points,

0:04:53.560,0:04:54.760
but everywhere else they'll be different.

0:04:54.760,0:04:56.960
Justin: Yes. Exactly.

0:04:56.960,0:05:02.520
This is almost the only fact you need 
to design efficient interactive proofs.

0:05:02.520,0:05:07.360
Even though interactive proofs 
use multivariate polynomials,

0:05:07.360,0:05:10.280
kind of each round of the interaction 
involves a univariate one.

0:05:10.280,0:05:15.240
So you really only ever for the most 
part apply this univariate fact.

0:05:15.240,0:05:19.720
There is a multivariate analog of this 
fact called the Schwartz–Zippel lemma,

0:05:19.720,0:05:23.080
which might come up later in this session.

0:05:23.080,0:05:26.080
But anyway, this is for the 
most part all you need to know.

0:05:26.080,0:05:29.000
So nothing beyond 8th grade.

0:05:29.000,0:05:29.702
Tracy: Cool.

0:05:29.702,0:05:30.240
Justin: Great.

0:05:30.240,0:05:32.240
So that's univariate polynomials.

0:05:32.240,0:05:40.760
But as already mentioned, the Sum-Check 
Protocol uses multivariate polynomials.

0:05:40.760,0:05:49.880
And so it is helpful to introduce the 
notion of multilinear polynomials.

0:05:49.880,0:05:53.000
Now, you don't need to know 
about multilinear polynomials

0:05:53.000,0:05:54.560
to understand the Sum-Check Protocol,

0:05:54.560,0:05:59.640
but you do typically need them 
to understand applications of it.

0:05:59.640,0:06:02.280
Typically, the polynomials 
that Sum-Check gets applied to

0:06:02.280,0:06:06.360
are kind of built out of 
several multilinear polynomials.

0:06:06.360,0:06:10.760
So in order to understand how the Sum-Check 
gets applied, we do need to discuss this.

0:06:10.760,0:06:27.920
So this is just let's say n-variate polynomials 
of degree at most one in each variable.

0:06:27.920,0:06:28.560
Okay.

0:06:31.240,0:06:33.920
So an example of a multilinear polynomial,

0:06:33.920,0:06:39.400
let's say in three variables, 
x₁, x₂, and x₃ would be,

0:06:39.400,0:06:48.120
let's say 3 * x₁ * x₂ * x₃ + x₁ * x₂.

0:06:48.120,0:06:54.200
Okay. But if I were to add in a term x1 
squared, it would not be multilinear anymore.

0:06:54.200,0:06:55.560
Okay.
Tracy: Because that term is not linear.

0:06:55.560,0:06:59.720
Justin: Yeah. Because of the exponent 
of 2 in a -- for a single variable.

0:06:59.720,0:07:00.440
You know this --

0:07:00.440,0:07:03.080
You know, if the exponent was 3, 
it would also not be multilinear.

0:07:03.080,0:07:05.640
So as long as you look at each variable

0:07:05.640,0:07:09.340
and its exponent is 1 in every 
single term, you're multilinear.

0:07:09.340,0:07:10.720
Tracy: Got it.

0:07:10.720,0:07:11.720
Justin: Okay.

0:07:12.680,0:07:16.200
Now while we're talking about 
multilinear polynomials,

0:07:16.200,0:07:23.200
we might as well also talk about what 
are called multilinear extensions.

0:07:23.200,0:07:23.960
Okay.

0:07:23.960,0:07:28.040
And here the motivation for what 
I'm about to describe comes from

0:07:28.040,0:07:30.840
the fact that the Sum-Check Protocol was computing

0:07:30.840,0:07:35.480
a sum over inputs in the 
Boolean hypercube {0,1}ⁿ.

0:07:35.480,0:07:35.640
Okay.

0:07:35.640,0:07:40.160
So let me draw like just a 
2-variate polynomial here.

0:07:40.160,0:07:43.240
So say --

0:07:43.240,0:07:45.240
Okay. So, right --

0:07:45.880,0:07:46.560
Yeah. There we go.

0:07:46.560,0:07:52.135
So forget about poly --

0:07:52.135,0:07:52.560
Forget about polynomials for a second.

0:07:52.560,0:07:58.520
Let's just say we have a function 
whose domain is {0,1} * {0,1}.

0:07:58.520,0:08:01.800
So there's only four possible 
inputs to the function.

0:08:01.800,0:08:04.720
And its outputs live in some finite field.

0:08:04.720,0:08:09.080
But just think of its outputs as numbers, 
if you're not comfortable with fields,

0:08:09.080,0:08:10.840
integers or something.

0:08:10.840,0:08:12.640
Okay. So let me draw a picture of f here.

0:08:12.640,0:08:23.000
So let's say I map 0,0 to 2, 0,1 
to 3, 1,0 to 4, and 1,1 to 5.

0:08:23.000,0:08:29.160
Okay. So if you give me any function 
whose domain is the Boolean hypercube,

0:08:29.160,0:08:32.760
so, {0,1}ⁿ for any n, here n is 2,

0:08:32.760,0:08:40.360
there always exists a unique 
multilinear polynomial 

0:08:40.360,0:08:44.280
that has the same behavior as the function

0:08:44.280,0:08:48.360
when you look at the polynomial 
only over the hypercube.

0:08:48.360,0:08:52.160
Remember, you can evaluate the 
polynomials outside the hypercube,

0:08:52.160,0:08:56.600
but this function we're "extending" 
is defined only over the hypercube.

0:08:56.600,0:08:57.380
Tracy: I see.

0:08:57.380,0:08:57.840
Justin: Okay.

0:08:57.840,0:09:01.200
So there's just a unique multilinear extension.

0:09:02.080,0:09:07.240
This means a multilinear polynomial p,

0:09:07.240,0:09:14.360
such that p(x) = f(x) 
for all x where f is defined,

0:09:14.360,0:09:16.480
which is the Boolean hypercube.

0:09:16.480,0:09:23.000
So I can draw the multilinear 
extensions evaluations in this example.

0:09:23.000,0:09:26.720
So whereas f only has four 
inputs, to p I can feed --

0:09:26.720,0:09:31.740
You know, for each of its two 
variables, I can feed any field element.

0:09:31.740,0:09:31.752
Tracy: Okay.

0:09:31.752,0:09:36.880
Justin: So the number of p is like extending 
the number of rows from 2 to field size

0:09:36.880,0:09:41.040
and extending the number of 
columns from 2 to field size.

0:09:41.040,0:09:44.040
So if this field has size 
like 2^128 or something,

0:09:44.040,0:09:47.700
there's like, the rows just go, go, 
go, go, go for like almost forever.

0:09:47.700,0:09:53.320
Tracy: So the goal is almost to reduce the 
evaluation domain down to this smaller domain?

0:09:53.320,0:09:54.400
Justin: So I would --

0:09:54.400,0:09:56.760
If you start with f, which has the small domain,

0:09:56.760,0:10:00.500
the goal of p is to extend the 
domain of f to the big one.

0:10:00.500,0:10:01.200
Tracy: I see.

0:10:01.200,0:10:01.340
Okay.

0:10:01.340,0:10:04.633
Justin: If you started with p and went to 
f, you'd be reducing the domain from p to --

0:10:04.633,0:10:05.680
Tracy: Yeah.
I guess I'm thinking of this.

0:10:05.680,0:10:07.720
This has like the full domain of the field,

0:10:07.720,0:10:10.026
and this has the narrow domain, which -- yeah.

0:10:10.026,0:10:12.200
Justin: Yeah. Yeah.
So typically the functions we care about,

0:10:12.200,0:10:15.800
that we want to use Sum-Check 
to compute or something,

0:10:15.800,0:10:18.800
are defined over the Boolean 
domain, over the small domain.

0:10:19.360,0:10:27.720
And the reason we want to deal with polynomials 
is for distance amplification purposes.

0:10:27.720,0:10:35.280
So roughly, if any two functions defined over 
the hypercube differ at even a single evaluation,

0:10:35.280,0:10:39.400
their multilinear extensions, well, are distinct.

0:10:39.400,0:10:43.080
And so that there are two different low 
degree polynomials that are not the same,

0:10:43.080,0:10:45.580
so they disagree almost 
everywhere over the big domain.

0:10:45.580,0:10:46.140
Tracy: That makes sense.

0:10:46.140,0:10:48.080
Justin: So it's a distance amplification thing.

0:10:48.080,0:10:49.040
Tracy: Okay.

0:10:49.040,0:10:52.160
Justin: So I wrote this, so it's 
really easy to actually write out,

0:10:52.160,0:10:54.920
figure out what the multilinear 
extension kind of looks like.

0:10:54.920,0:10:57.400
So in any direction it's linear, right?

0:10:57.400,0:11:02.560
So if you go from 2 to 4, the difference is 2.

0:11:03.200,0:11:05.280
So if you go one more step, it's 6.

0:11:07.600,0:11:10.120
If you go another step, it's 8 and so forth.

0:11:10.120,0:11:13.480
Similarly, 3 to 5, this one is 2. So 7 and 9 --

0:11:13.480,0:11:17.680
And then going in this direction, 
2 to 3, one step is 2 to 3.

0:11:17.680,0:11:19.600
So if I go another step, I have 4.

0:11:19.600,0:11:22.440
If I go another step, I have 5, and so forth.

0:11:22.440,0:11:29.400
So going left to right, you go up 
1, and top to bottom you go up 2.

0:11:29.400,0:11:30.540
That's the multilinear extension.

0:11:30.540,0:11:32.200
Tracy: I see. Okay.

0:11:32.200,0:11:38.000
Justin: Now note, any 
function over the small domain

0:11:38.000,0:11:42.720
has many polynomials that extend 
it, but only one is multilinear.

0:11:42.720,0:11:43.360
Okay.

0:11:43.360,0:11:46.880
So for this particular example,

0:11:46.880,0:11:50.800
I'll actually just write out an 
expression for the multilinear extension

0:11:50.800,0:11:54.760
and then give you another 
extension that's not multilinear.

0:11:54.760,0:11:57.680
Maybe we'll do one quick example after that

0:11:57.680,0:11:59.240
and then we're ready for Sum-Check.

0:12:00.160,0:12:00.680
Okay.

0:12:00.680,0:12:07.480
So for this picture, the multilinear 
extension can be written as follows.

0:12:07.480,0:12:07.880
This is --

0:12:07.880,0:12:10.760
What I'm going to do is a procedure 
called Lagrange interpolation,

0:12:10.760,0:12:12.920
although that fact doesn't matter.

0:12:12.920,0:12:14.520
So --

0:12:14.520,0:12:19.620
All right. This function maps input 0,0 to 2.

0:12:19.620,0:12:20.420
Tracy: Yep.

0:12:20.420,0:12:20.800
Justin: Okay.

0:12:20.800,0:12:21.793
So the first term --

0:12:21.793,0:12:24.360
Tracy: So what you're trying to 
do is say, given this domain,

0:12:24.360,0:12:27.640
I'm going to create a polynomial 
that fits these evaluations,

0:12:27.640,0:12:29.403
or that evaluates this domain.

0:12:29.403,0:12:30.320
Justin: Exactly.

0:12:30.320,0:12:31.040
Tracy: Yeah.

0:12:31.040,0:12:32.760
Justin: So --

0:12:32.760,0:12:36.880
Yeah. So in order to make sure 
that the polynomial map 0,0 to 2,

0:12:36.880,0:12:41.840
I'm going to have a 2 * (1-x₁) * (1-x₂)

0:12:41.840,0:12:43.720
Tracy: So you're making this a root.

0:12:43.720,0:12:50.000
Justin: Well, what we're doing is without 
the 2, this sort of picks out input 0,0.

0:12:50.000,0:12:50.520
Tracy: I see.

0:12:50.520,0:12:50.792
Okay. Yeah.

0:12:50.792,0:12:53.240
Justin: So 0,0 maps to 1 
and any other Boolean input.

0:12:53.240,0:12:54.600
Tracy: All right. It's like switching.

0:12:54.600,0:12:58.040
You're essentially saying, 
I'm going to switch 2 on.

0:12:58.040,0:13:00.080
So this is 2 on, essentially.

0:13:00.080,0:13:02.360
And then you're going to 
write it again to switch 3 on.

0:13:02.360,0:13:03.480
Justin: Yeah, yeah.

0:13:03.480,0:13:08.080
So this just sort of turns input 
0,0 on and everything else off.

0:13:08.080,0:13:10.873
And then 2 means multiplied by 2 gives you 2.

0:13:10.873,0:13:11.920
Tracy: Gives you 2.

0:13:11.920,0:13:17.480
Justin: And then if I want to turn input 
0,1 on, I'm going to multiply that by 3.

0:13:17.480,0:13:20.840
So I got 1-x₁ to make sure 0 is on.

0:13:20.840,0:13:21.480
Tracy: Yep.

0:13:21.480,0:13:23.740
Justin: Times x₂ to make sure 1 is on.

0:13:23.740,0:13:25.000
Tracy: Got it.

0:13:25.000,0:13:32.000
Justin: And then we have 4 * x₁ * (1-x₂),

0:13:32.000,0:13:34.800
which turns 1,0 on and maps it to 4.

0:13:34.800,0:13:40.960
And then finally 5 * x₁ * x₂, which turns, 1,1 on.

0:13:40.960,0:13:42.027
Tracy: Got it. Okay.

0:13:42.027,0:13:44.360
Justin: Yeah.
So that's Lagrange interpolation.

0:13:44.360,0:13:48.080
But just to be clear, so this is 
the unique multilinear polynomial

0:13:48.080,0:13:53.040
that extends this 2-variate function f.

0:13:53.040,0:13:53.760
Tracy: Okay.

0:13:53.760,0:13:55.360
Justin: But I can add things to --

0:13:55.360,0:14:00.040
If I don't want it to be multilinear, 
I can add all sorts of things to it

0:14:00.040,0:14:03.320
and preserve the behavior 
over the small domain. Right?

0:14:03.320,0:14:07.680
So I can add in like x₁ * (1-x₁)

0:14:07.680,0:14:12.059
and over the small domain, nothing changed 
because this evaluates to 0 over the small domain.

0:14:12.059,0:14:12.920
Tracy: I see.
Justin: Right.

0:14:12.920,0:14:16.280
x1 equals 0 kills this. x₁
equals 1 also kills this.

0:14:16.280,0:14:17.000
Tracy: Yeah.

0:14:17.000,0:14:21.520
Justin: So there's sort of an infinite 
number of non multilinear extensions,

0:14:21.520,0:14:25.260
but only there's exactly one 
multilinear extension of anything.

0:14:25.260,0:14:26.880
Tracy: Interesting. Okay.

0:14:26.880,0:14:27.760
Justin: Great.

0:14:27.760,0:14:32.520
And again, so the reason these extension 
polynomials are so useful in proof systems is

0:14:32.520,0:14:36.320
because it's like if the prover 
lies about any little thing it did,

0:14:36.320,0:14:39.200
you need the verifier to pick up on the lie.

0:14:39.200,0:14:42.560
So we need little teeny differences 
between something that's perfectly right

0:14:42.560,0:14:46.640
and something that's off by a little to 
get blown up into huge differences.

0:14:46.640,0:14:50.120
And so again, like if you 
took two different functions

0:14:50.120,0:14:53.240
over the small domain that 
differ even a single input,

0:14:53.240,0:14:56.860
their multilinear extensions are 
going to differ almost everywhere.

0:14:56.860,0:14:56.872
Tracy: Yeah.

0:14:56.872,0:14:59.040
Justin: So if you look at them at 
a random point, they'll differ.

0:14:59.040,0:15:00.640
Tracy: Yeah. Got it.

0:15:00.640,0:15:02.160
Justin: Okay.

0:15:02.160,0:15:03.549
And just so one example --

0:15:03.549,0:15:04.400
Tracy: And the goal really here --

0:15:04.400,0:15:05.240
Sorry to interrupt.

0:15:05.240,0:15:07.800
The goal really here is to prove that the --

0:15:07.800,0:15:09.960
Is for the verifier to be able to demonstrate that

0:15:09.960,0:15:14.240
the prover has used this polynomial 
throughout all of its operations.

0:15:14.240,0:15:17.240
Justin: Ultimately, that's kind 
of what happens in the SNARKs.

0:15:17.240,0:15:21.000
And we'll see as we see applications of 
Sum-Check that will become much, much clearer.

0:15:21.000,0:15:21.960
Tracy: Okay.

0:15:21.960,0:15:26.040
And maybe one thing I wanted to 
understand, so this makes sense,

0:15:26.040,0:15:28.280
like it's captured this domain.

0:15:30.000,0:15:32.360
Is this the multilinear extension?

0:15:32.360,0:15:35.300
Like and is adding these 
additional terms extending this?

0:15:35.300,0:15:40.160
Justin: Oh no. When you add non multilinear 
terms, you still have an extension,

0:15:40.160,0:15:42.900
meaning it has the right 
behavior over the small domain.

0:15:42.900,0:15:43.920
Tracy: Correct.

0:15:43.920,0:15:45.760
Justin: But it's not multilinear anymore.

0:15:45.760,0:15:48.760
So this right here, without any --

0:15:48.760,0:15:55.480
This is the multilinear extension of the fs that 
map 0,0 to 2, 0,1 to 3, 1,0 to 4 and 1,1 to 5.

0:15:55.480,0:15:56.540
This is it. This is multilinear.

0:15:56.540,0:15:57.300
Tracy: Okay. Got it.

0:15:57.300,0:15:59.000
Justin: There are other extensions 
that are not multilinear.

0:15:59.000,0:16:01.920
Tracy: I understand. Okay.

0:16:01.920,0:16:02.780
Okay. Cool.

0:16:02.780,0:16:06.280
Justin: Great. And now, so 
I'll just do one more example.

0:16:06.280,0:16:09.460
It's a really important one. I 
call it the equality function.

0:16:09.460,0:16:10.180
Tracy: Yeah.

0:16:10.180,0:16:12.440
Justin: Okay. So here, this is going to take --

0:16:12.440,0:16:19.600
This is -- take two inputs, say x and y.

0:16:19.600,0:16:27.000
So eq(x, y), where both 
of them are in {0,1}ⁿ.

0:16:27.000,0:16:32.880
Okay. And it's going to spit out --

0:16:32.880,0:16:40.020
So we're defining eq to spit out 1 if x 
and y are the same vectors and 0 otherwise.

0:16:40.020,0:16:43.080
Tracy: I see. Okay.

0:16:43.080,0:16:46.673
Justin: Okay. And so the multilinear extension --

0:16:46.673,0:16:51.180
Tracy: So it's going to take a different form 
from this, which enforces this characteristic.

0:16:51.180,0:16:52.720
Justin: Right. Right. Exactly.

0:16:52.720,0:16:55.600
So note like the number of terms --

0:16:55.600,0:16:59.680
When I did Lagrange interpolation, the 
number of terms was 2ⁿ. Right?

0:16:59.680,0:17:02.900
There was one term for every 
input in the small domain.

0:17:02.900,0:17:02.912
Tracy: Yeah.

0:17:02.912,0:17:09.660
Justin: We're going to see that eq can actually be 
evaluated in its multilinear extension in time n.

0:17:09.660,0:17:10.380
Tracy: I see.

0:17:10.380,0:17:12.920
Justin: Okay.
So basically, if you have really nice functions,

0:17:12.920,0:17:15.640
you can evaluate them faster 
than going like term by term

0:17:15.640,0:17:19.400
through this Lagrange interpolation definition.

0:17:19.400,0:17:20.320
So --

0:17:20.320,0:17:22.920
By the way, whenever I have a 
function over the small domain

0:17:22.920,0:17:25.320
and I want to refer to its 
multilinear extension polynomial,

0:17:25.320,0:17:27.000
I just stick a twiddle over it.

0:17:27.000,0:17:28.440
So this is not a polynomial.

0:17:28.440,0:17:31.840
It's just a function defined 
over that Boolean hypercube.

0:17:31.840,0:17:35.040
If I stick a twiddle over it, it's a polynomial.

0:17:35.040,0:17:35.352
Tracy: Okay.

0:17:35.352,0:17:38.040
Justin: And so --

0:17:38.040,0:17:43.320
Yeah, so let's say the inputs 
here are like x₁ to xₙ, y₁ to yₙ.

0:17:43.320,0:17:44.240
Okay. So what is this?

0:17:44.240,0:17:46.240
So --

0:17:46.240,0:17:52.640
I'm just going to write it and then 
we'll explain why this equality is true.

0:17:52.640,0:17:56.320
So we have xi -- so it's a product of n things

0:17:56.320,0:18:03.960
where the "i" thing is xᵢ*yᵢ + (1-xᵢ) * (1-yᵢ).

0:18:03.960,0:18:05.200
Okay?

0:18:05.200,0:18:09.280
So let's call this a claim, if you will. Because 
I haven't explained why this is true yet.

0:18:09.280,0:18:10.120
Tracy: Yeah.

0:18:10.120,0:18:10.800
Justin: Okay.

0:18:10.800,0:18:14.720
So to see why it's true, you 
just have to check two things.

0:18:14.720,0:18:18.200
One, check that the right-hand 
side is a multilinear polynomial.

0:18:18.200,0:18:19.600
And it is. Right?

0:18:19.600,0:18:21.840
Because everything has degree 1.

0:18:21.840,0:18:23.040
Tracy: Yeah.

0:18:23.040,0:18:23.880
Justin: Yeah. The --

0:18:23.880,0:18:28.480
Any two terms of the product involve different 
variables. So no variable has degree 2.

0:18:28.480,0:18:34.760
So all we have to do to confirm that it is the 
multilinear extension of this equality function

0:18:34.760,0:18:39.000
is make sure that if you feed in 
any two Boolean vectors x and y,

0:18:39.000,0:18:42.480
this polynomial spits out 
whatever equality it spits out.

0:18:42.480,0:18:43.300
Tracy: Yeah. I see.

0:18:43.300,0:18:46.720
Justin: Okay. So what's happening here 
is we're going over each and every bit.

0:18:46.720,0:18:49.320
Tracy: So the outcome of this is always 0 or 1.

0:18:49.320,0:18:49.920
Justin: Yes.

0:18:49.920,0:18:50.490
Tracy: Yeah.

0:18:50.490,0:18:55.800
Justin: And so the i-th term is just checking, 
is the i-th bit of x equal to the i-th bit of y.

0:18:55.800,0:18:57.181
Right. If they're both 1, then this spits 
out 1, and this spits out 0, and you get 1.

0:18:57.181,0:19:03.240
If they're both 0, then this 
spits out 0, and this spits out 1.

0:19:03.240,0:19:07.880
And if one is 0 and the other is 
1, then both these terms are 0.

0:19:07.880,0:19:12.400
And so producting them together is 
saying for every i, does xᵢ equal yᵢ?

0:19:12.400,0:19:12.920
That's equality.

0:19:12.920,0:19:13.520
Tracy: Yeah.

0:19:13.520,0:19:16.746
It's just a way of encoding 
equality checks into a polynomial.

0:19:16.746,0:19:17.108
Justin: Yeah. Exactly.

0:19:17.108,0:19:17.935
Tracy: To a multilinear --

0:19:17.935,0:19:18.660
Justin: Exactly --
Tracy: Extended polynomial.

0:19:18.660,0:19:19.160
Justin: Exactly.

0:19:19.160,0:19:19.560
Tracy: Got it.

0:19:19.560,0:19:20.320
Justin: So this is a --

0:19:20.320,0:19:24.240
This comes up in lots of applications 
of the Sum-Check Protocol.

0:19:24.240,0:19:27.640
And you know, there are other nice examples 
just to get comfortable with it.

0:19:27.640,0:19:28.840
If I just had 2 --

0:19:28.840,0:19:31.360
Tracy: Is this the equality check, I guess?

0:19:31.360,0:19:33.160
Is that what it's called, or?

0:19:33.160,0:19:35.560
I guess it ladders up to 
an equality check somehow.

0:19:35.560,0:19:37.280
Justin: Yeah. The equality --

0:19:37.280,0:19:40.160
So this is especially useful -- 
well, it's useful all over the place,

0:19:40.160,0:19:46.160
but definitely comes up in what we 
call zerochecks, but we'll see soon.

0:19:46.160,0:19:50.619
Basically, zerochecks mean you want 
to checkd: does everything equal zero?

0:19:50.619,0:19:50.632
Tracy: I see.

0:19:50.632,0:19:53.600
Justin: So you test equality 
with zero sort of thing. Yeah.

0:19:54.480,0:19:55.480
Just one last example,

0:19:55.480,0:20:03.320
I guess if I want to compute the OR, of 
just two inputs like x₁, y₁, that is --

0:20:03.320,0:20:09.960
the multilinear extension of that 
is x₁ + y₁ - x₁ * y₁.

0:20:09.960,0:20:11.080
And you can just -- you know, you can --

0:20:11.080,0:20:12.520
there are only four possible inputs to it.

0:20:12.520,0:20:12.870
You can just --

0:20:12.870,0:20:15.260
Tracy: If you go through the 
table, then this plays out.

0:20:15.260,0:20:15.940
Justin: Yeah. Yeah.

0:20:15.940,0:20:16.400
Tracy: Okay.

0:20:16.400,0:20:18.880
Justin: Yeah. So there are other 
simple ones that are good to look at,

0:20:18.880,0:20:22.760
You know, XOR, AND -- just get comfortable with it

0:20:23.920,0:20:27.000
Okay. So that's just getting comfortable 
with multivariate polynomials

0:20:27.000,0:20:28.440
and multilinear ones in particular.

0:20:28.440,0:20:30.420
And now we're ready for the Sum-Check Protocol.

0:20:30.420,0:20:32.240
Tracy: All right.

0:20:32.240,0:20:33.800
Justin: Okay.

0:20:33.800,0:20:38.840
So let's see how the Sum-Check Protocol works 
and then we'll see some applications of it.

0:20:38.840,0:20:42.920
So remember, the goal in the 
Sum-Check Protocol is to compute

0:20:42.920,0:20:52.840
the sum over all x in {0,1}ⁿ of g(x) for 
some "low degree" polynomial g and n variables.

0:20:52.840,0:20:57.000
Again, we'll see applications where 
then you'll know what this g is.

0:20:57.000,0:21:00.280
However, I will mention that 
in most SNARK applications,

0:21:00.920,0:21:06.840
the number of terms in the sum 
you should think of as roughly --

0:21:06.840,0:21:10.880
So terms being summed, you should think of as like

0:21:10.880,0:21:17.360
the size of the circuit that the 
prover is making a claim about.

0:21:17.360,0:21:19.880
So there's like one term in the 
sum for every gate in the circuit

0:21:19.880,0:21:23.080
or one term in the sum for every 
constraint in your constraint system,

0:21:23.080,0:21:30.440
which means little n, the number of 
variables, is log of size of circuit

0:21:30.440,0:21:34.866
or number of constraints or whatever.

0:21:34.866,0:21:39.880
Tracy: Right. Okay. So we have 
a circuit of length 2ⁿ.

0:21:39.880,0:21:42.240
Justin: Yes. Yeah.

0:21:42.240,0:21:47.980
And so, remember in Sum-Check, there will 
be as we'll see one round per variable.

0:21:47.980,0:21:47.992
Tracy: Yeah.

0:21:47.992,0:21:54.040
Justin: Okay. Which means in SNARK applications, 
one round -- like log circuit size many rounds.

0:21:54.040,0:21:55.400
Which means in Sum-Check-based SNARKs,

0:21:55.400,0:21:58.980
the verifier is roughly going 
to run in log circuit size time.

0:21:58.980,0:21:59.580
Tracy: Got it.

0:21:59.580,0:22:00.920
Justin: Which is actually pretty good.

0:22:00.920,0:22:04.720
You know, there's a lot of poly logs 
out there that are much more than log,

0:22:04.720,0:22:05.580
like logic cubed.

0:22:05.580,0:22:07.680
Tracy: This is kind of reminiscent of FRI to me.

0:22:07.680,0:22:12.300
We're going to kind of reduce the amount of 
work over time by doing log n rounds of work.

0:22:12.300,0:22:14.520
Justin: Yes. It's also 
reminiscent of Bulletproofs.

0:22:14.520,0:22:19.280
And topic for another presentation, but 
Bulletproofs literally is Sum-Check.

0:22:19.280,0:22:21.040
So if you know Bulletproofs, you 
actually already know Sum-Check,

0:22:21.040,0:22:23.100
although you probably don't realize 
that you already know Sum-Check.

0:22:23.100,0:22:23.780
Tracy: Okay.

0:22:23.780,0:22:24.960
Justin: Okay.

0:22:24.960,0:22:27.920
So there's exactly, like the size 
of the problem we're dealing with

0:22:27.920,0:22:29.640
it's going to halve in every round.

0:22:29.640,0:22:33.520
And in fact, every round, what it's going to 
do is sort of split the problem into two halves

0:22:33.520,0:22:37.920
and take like a random combination of the two 
halves to get a problem instance of half the size.

0:22:37.920,0:22:38.800
Tracy: Awesome.

0:22:38.800,0:22:39.280
Justin: Okay.

0:22:39.280,0:22:43.080
So at the start of the 
protocol, kind of round zero,  

0:22:43.080,0:22:48.560
the prover will send like a claimed answer, C₀.

0:22:48.560,0:22:52.000
And the verifier says, hey, prover, 
I don't trust that you're honest.

0:22:52.000,0:22:54.660
Convince me that the claimed answer is C₀.

0:22:54.660,0:22:54.672
Tracy: Okay.

0:22:54.672,0:23:01.073
Justin: And the prover is going to say, all right, 
this is how I'm going to convince you. So --

0:23:01.073,0:23:03.020
Tracy: And there's a consistency check, right?

0:23:03.020,0:23:07.880
Justin: There will be a consistency check 
between the prover's round one message,

0:23:07.880,0:23:11.280
which I'll define in a second, 
and this claimed answer, C₀.

0:23:11.280,0:23:14.600
So I'll try not to forget the consistency check.

0:23:14.600,0:23:23.800
So the prover is going to 
send a univariate polynomial,

0:23:23.800,0:23:29.180
let me call it s₁, and variable capital X₁.

0:23:29.180,0:23:30.280
Tracy: Yeah.

0:23:30.280,0:23:36.440
Justin: Which if the prover's honest, it will 
equal the following univariate polynomial.

0:23:37.160,0:23:39.800
So the honest polynomial, I'm going to call h₁.

0:23:39.800,0:23:42.800
But if the prover is cheating, it might 
send an s₁ that's not equal to h₁.

0:23:42.800,0:23:49.680
So h1 will be defined as a 
sum over slightly fewer terms.

0:23:49.680,0:23:58.680
So what we're going to do now is we're going 
to sum over everything but the first variable.

0:23:58.680,0:24:04.400
So we're going to leave the first 
variable sort of not summed over,

0:24:04.400,0:24:06.360
just a free variable,

0:24:07.160,0:24:13.000
but we are still going to sum over Boolean 
values for the last n - 1 variables.

0:24:13.000,0:24:14.120
Tracy: Got it.

0:24:14.120,0:24:14.840
Justin: Okay.

0:24:14.840,0:24:22.560
Now, this message is specifically designed 
so that if the prover is honest, then --

0:24:22.560,0:24:26.680
You know, so if s₁ equals h₁, 
then the following will hold.

0:24:26.680,0:24:36.800
So if s₁ equals what it should equal, 
then the claimed answer will equal

0:24:36.800,0:24:42.400
or the true answer will equal 
s₁(0) plus s₁(1). Right?

0:24:42.400,0:24:45.840
Because we define h₁ to just not 
sum over that first variable.

0:24:45.840,0:24:49.580
If you then go back and sum over that first 
variable, you should get out the actual answer.

0:24:49.580,0:24:50.880
Tracy: Got it.

0:24:50.880,0:24:54.680
Justin: And again, when we said 
that each round of Sum-Check

0:24:54.680,0:24:57.840
sort of takes the big problem 
instance over 2ⁿ terms

0:24:57.840,0:25:01.880
and splits it into two halves and like takes 
a random linear combination of the two halves,

0:25:01.880,0:25:03.280
these are the two halves.

0:25:03.280,0:25:10.440
So this is capturing the terms where x₁ is 0.

0:25:10.440,0:25:18.240
Right? If you feed 0 into h₁, that's 
like feeding 0 in for the first variable.

0:25:18.240,0:25:20.320
And if you feed 1 in, it's like 
feeding 1in for the first --

0:25:20.320,0:25:21.586
So those are the two halves where --

0:25:21.586,0:25:22.872
Tracy: So you split the 
terms into two halves. I see.

0:25:22.872,0:25:24.320
Justin: Exactly.

0:25:25.600,0:25:31.240
And now to compare to like 
Bulletproofs or maybe FRI is easier.

0:25:31.240,0:25:32.920
No. For both of them.

0:25:33.440,0:25:35.800
This is like the magic of Sum-Check.

0:25:35.800,0:25:42.560
For FRI or Bulletproofs, you split 
the big thing into two halves

0:25:42.560,0:25:45.240
and the prover would 
cryptographically commit to each half.

0:25:45.240,0:25:46.820
Here, there's no commitments, 
there's no cryptography.

0:25:46.820,0:25:47.720
Tracy: I see.

0:25:47.720,0:25:50.960
Justin: So that's one of the 
amazing things about Sum-Check

0:25:50.960,0:25:53.440
and why it's so key to fast prover SNARKs.

0:25:53.440,0:25:55.880
Tracy: So it doesn't need to 
send a commitment to each half.

0:25:55.880,0:25:57.920
What does it send instead of a commitment?

0:25:57.920,0:26:00.833
Justin: So it just sends s₁. Okay?

0:26:00.833,0:26:02.440
Tracy: Which is a low degree polynomial.

0:26:02.440,0:26:04.440
Justin: Very low degree, and only in one variable.

0:26:04.440,0:26:10.440
So let's say just for concreteness 
that g has degree 2 in each variable.

0:26:10.440,0:26:13.880
In most applications, g actually 
will have degree, like 3,

0:26:13.880,0:26:16.240
sometimes 2, sometimes a little more than 3.

0:26:16.240,0:26:20.200
But let's say 2 in each variable for simplicity

0:26:21.320,0:26:27.840
Now note, like a univariate polynomial 
of degree 2 only has three coefficients.

0:26:29.320,0:26:33.480
And so s₁ and h₁, they're 
univariate polynomials of degree 2.

0:26:33.480,0:26:36.120
So the prover is just sending s 
-- it's just 3 field elements.

0:26:36.120,0:26:39.520
It turns out, actually you don't even need 
the prover to send all three field elements

0:26:39.520,0:26:46.400
because this check is only going to 
pass if s₁(1) = C₀ - s₁(0).

0:26:46.400,0:26:49.240
So you don't even need the prover to send.

0:26:49.240,0:26:50.960
You can kind of get rid of a field element

0:26:50.960,0:26:55.347
by just inferring 1 degree of 
freedom from this check passing.

0:26:55.347,0:26:55.480
Tracy: I got you.

0:26:55.480,0:26:57.120
Justin: If it were anything 
else, the check would fail.

0:26:57.120,0:27:00.600
So just why not just assume it passes.

0:27:00.600,0:27:03.800
So very, very small messages in each round?

0:27:03.800,0:27:05.400
And there's one round per variable.

0:27:05.400,0:27:09.200
So the total proof size winds up 
being like after the optimizations,

0:27:09.840,0:27:13.720
two log circuit size or something 
like that, many field elements.

0:27:13.720,0:27:15.120
Tracy: I see.

0:27:15.120,0:27:17.560
So every round you're going 
to pass over 2 field elements

0:27:17.560,0:27:18.920
it can do the evaluation then,

0:27:18.920,0:27:21.080
and then you're going to 
repeat that for log n rounds?

0:27:21.080,0:27:22.480
Justin: Right. Exactly.

0:27:22.480,0:27:27.360
Now, the problem is, right now I've 
only told you the round one message.

0:27:27.360,0:27:29.140
So why are we not like done? Right?

0:27:29.140,0:27:29.152
Tracy: Yeah.

0:27:29.152,0:27:33.400
Justin: And the issue is the verifier 
doesn't actually know what h₁ is. Right?

0:27:33.400,0:27:35.400
It's defined in terms of this pretty big sum,

0:27:35.400,0:27:39.040
which is like half the size of 
the original sum, but still big.

0:27:39.040,0:27:40.000
Tracy: Yeah.

0:27:40.000,0:27:42.820
Justin: So it doesn't actually 
know does s₁ equal h₁?

0:27:42.820,0:27:43.560
Tracy: Yeah.

0:27:43.560,0:27:44.840
Justin: Yeah.

0:27:44.840,0:27:50.553
So that is the purpose of 
the next round. And so --

0:27:50.553,0:27:54.960
Tracy: It's checked sort of one constraint, 
but it hasn't checked all of h₁.

0:27:54.960,0:27:55.840
Justin: That's right.

0:27:56.720,0:28:00.080
So the consistency check, which I 
need to make sure not to forget,

0:28:00.080,0:28:02.360
is that after the prover sends s₁,

0:28:02.360,0:28:13.120
the verifier checks that s₁(0) + s₁(1) 
indeed equals the claimed answer.

0:28:13.120,0:28:15.640
That's asking like are these two pieces

0:28:15.640,0:28:20.040
actually consistent with the original 
claim that had just one piece.

0:28:20.560,0:28:24.560
And then the verifier needs to check 
like, are these two pieces honest?

0:28:24.560,0:28:27.720
That is, does s₁ actually equal h₁?

0:28:27.720,0:28:28.220
Okay.

0:28:33.560,0:28:36.520
And now the prover explicitly 
sent s₁ to the verifier.

0:28:36.520,0:28:38.720
It's just three coefficients.

0:28:39.640,0:28:44.800
And so the verifier actually knows 
s₁. But the verifier does not know h₁.

0:28:44.800,0:28:45.310
Tracy: Right.

0:28:45.310,0:28:50.240
Justin: Okay. So how is the verifier going 
to check this when it doesn't know h₁?

0:28:50.240,0:28:54.080
Well, let me make things a little simpler, 
although it's not the end of the story.

0:28:54.080,0:29:01.200
The verifier is just going to pick a 
random field element, a random input to s₁,

0:29:01.200,0:29:06.660
So sends that field element to -- 
let me call it r₁, to the prover.

0:29:06.660,0:29:10.040
Tracy: And it asks it to evaluate h₁ at that r₁.

0:29:10.040,0:29:12.720
Justin: Right. Right. And then, you know --

0:29:12.720,0:29:15.720
And now wants to confirm --

0:29:15.720,0:29:23.320
And this is what the round two is going to be 
targeted at, that s₁(r₁) = h₁(r₁).

0:29:23.320,0:29:26.240
Now, the verifier on its own can 
compute s₁(r₁). It knows s₁.

0:29:26.240,0:29:28.120
But it doesn't know h₁(r₁).

0:29:28.120,0:29:33.380
So it's going to use round two of 
Sum-Check to try to compute h₁(r₁).

0:29:33.380,0:29:37.600
Tracy: And what this does is it 
lets the verifier confirm that

0:29:37.600,0:29:42.600
this s1 is a univariate 
polynomial of the larger whole.

0:29:42.600,0:29:47.040
Justin: It lets the prover confirm that 
s1 actually equals what it should, h₁.

0:29:47.040,0:29:48.320
And if it does equal what it should,  

0:29:48.320,0:29:51.660
then the claimed answer is indeed 
correct by the consistency check.

0:29:51.660,0:29:53.640
Tracy: I see.

0:29:53.640,0:29:54.720
Okay.

0:29:54.720,0:29:55.960
Justin: Yeah. And this --

0:29:55.960,0:29:57.760
You know, there's a way to picture this as --

0:29:57.760,0:30:00.760
You know, we split the sum into two halves.

0:30:00.760,0:30:03.520
The first half is where the 
first variable is fixed to 0,

0:30:03.520,0:30:05.800
and the second half is where the 
first variable is fixed to 1.

0:30:05.800,0:30:10.160
And the fixing the first variable to r₁

0:30:10.160,0:30:13.320
is like taking a random linear 
combination of the two halves sort of.

0:30:13.320,0:30:15.980
And so you sort of collapse the 
two halves together into one.

0:30:15.980,0:30:16.880
Tracy: Fold them together.

0:30:16.880,0:30:18.640
Justin: Yeah. Fold them together.

0:30:18.640,0:30:24.280
And the key point here is that h₁(r₁) is --

0:30:24.280,0:30:26.720
Let me just stick r₁ in here. Right?

0:30:26.720,0:30:28.040
Is --

0:30:29.080,0:30:32.480
Well, it's exactly the kind of statement 
we designed Sum-Check to prove,

0:30:32.480,0:30:36.040
except now we're applying it to a 
polynomial with one fewer variable.

0:30:36.040,0:30:44.600
So rather than apply Sum-Check to G 
itself, apply it to the polynomial --

0:30:44.600,0:30:45.480
Let me call it, I don't know,  

0:30:45.480,0:30:54.240
g star of x₂ to xₙ obtained from g just 
by fixing the first variable to r₁.

0:30:54.240,0:30:57.040
Tracy: Right. You reduce the problem a little bit.

0:30:57.040,0:30:58.160
Justin: Yeah. Exactly.

0:30:58.160,0:31:03.520
So you keep doing this round 
over round, and then at the --

0:31:03.520,0:31:08.920
So after one round, variable 
1 has been fixed to r₁.

0:31:08.920,0:31:13.920
So the prover is making -- you 
know, proving the value of h₁(r₁),

0:31:14.440,0:31:18.080
which, remember, is like g of r₁ with other stuff.

0:31:18.080,0:31:22.880
After round two, the prover makes 
a claim about like h₂(r₂),

0:31:22.880,0:31:28.080
which will be g with first variable 
fixed r₁, the second variable fixed r₂.

0:31:28.080,0:31:31.840
And eventually you get to the nth 
round, one round per variable.

0:31:31.840,0:31:36.920
And at the end of that round, the prover makes 
a claim about g with all variables fixed.

0:31:36.920,0:31:41.520
And that claim, the verifier 
is going to compute on its own

0:31:41.520,0:31:46.880
because we said the whole point of 
Sum-Check is to reduce the original claim,

0:31:46.880,0:31:51.080
which involves 2ⁿ evaluations 
of g, to evaluating g at a single point.

0:31:51.080,0:31:51.700
We've done that.

0:31:51.700,0:31:52.240
Tracy: Got it.

0:31:52.240,0:31:53.680
Justin: But now we're going to have to talk about,

0:31:53.680,0:31:58.160
in applications, can the verifier actually 
get that one evaluation quickly or not?

0:31:58.160,0:32:00.760
And that kind of varies. And 
we'll talk about that more.

0:32:00.760,0:32:05.520
Tracy: Okay. Cool. It might be useful to 
see how this kind of maps onto like an R1CS,

0:32:05.520,0:32:07.320
like a constraint system of some kind.

0:32:07.320,0:32:08.920
Justin: Great.

0:32:08.920,0:32:13.560
So that actually is the first 
application I wanted to cover.

0:32:14.720,0:32:17.600
And we'll also make kind of 
what's going on in the protocol,

0:32:17.600,0:32:19.840
I think, a little more concrete.

0:32:20.960,0:32:23.160
Let me leave this up here for now --

0:32:23.160,0:32:24.040
Actually, let --

0:32:24.040,0:32:26.860
Let me leave the goal up here. 
And get rid of everything else.

0:32:26.860,0:32:27.840
Tracy: Sounds good.

0:32:29.160,0:32:30.880
Justin: Okay.

0:32:30.880,0:32:33.240
Maybe I'll start with the picture and then,

0:32:33.920,0:32:35.640
before I get a little more formal.

0:32:35.640,0:32:42.520
So in R1CS, there are three matrices 
known to both prover and verifier.

0:32:42.520,0:32:48.360
They're called constraint matrices, 
and they call them A, B and C.

0:32:48.360,0:32:49.120
Okay.

0:32:49.680,0:32:51.200
And the --

0:32:51.200,0:32:52.520
So these are matrices.

0:32:52.520,0:32:59.360
So maybe I'll say they have capital 
M rows and capital N columns.

0:32:59.360,0:33:00.480
Tracy: Yeah.

0:33:00.480,0:33:11.040
Justin: And the prover claims 
to know a z, such that (Az) --

0:33:11.040,0:33:17.340
So that's matrix-vector product, 
entry wise, product (Bz) equals (Cz).

0:33:17.340,0:33:18.440
Tracy: Yep.

0:33:18.440,0:33:18.920
Justin: Okay.

0:33:18.920,0:33:23.480
Now I'm going to give these 
matrix-vector products a name.

0:33:23.480,0:33:27.040
So let's say little a, little b and little c.

0:33:27.040,0:33:27.760
Tracy: Okay.

0:33:27.760,0:33:28.280
Justin: Okay.

0:33:28.280,0:33:36.880
So the claim is that for every 
constraint, every row of these matrices.

0:33:36.880,0:33:41.360
Tracy: This is effectively evaluating 
the constraints of the SNARK

0:33:41.360,0:33:45.060
against a given witness and 
finding it at 0 for all.

0:33:45.060,0:33:45.489
Justin: Yeah.

0:33:45.489,0:33:47.920
Tracy: All constraints.
Justin: So, yeah, you should think of z as like,

0:33:47.920,0:33:50.980
roughly the witness the SNARK 
prover's claiming to know.

0:33:50.980,0:33:50.992
Tracy: Yeah.

0:33:50.992,0:33:56.920
Justin: And each row of these matrices 
together makes one constraint.

0:33:56.920,0:34:01.320
And so the prover's claiming to know 
a z that satisfies all M constraints.

0:34:01.320,0:34:03.680
And this capital N is like 
the size of the witness,

0:34:03.680,0:34:05.360
and this capital M is the number of constraints.

0:34:05.360,0:34:05.860
Tracy: Yeah.

0:34:06.120,0:34:06.620
Justin: Okay.

0:34:06.620,0:34:09.120
So the claim is that for every --

0:34:09.120,0:34:11.600
Every constraint is of the form ai --

0:34:11.600,0:34:15.560
Little aᵢ times little bᵢ equals little cᵢ.

0:34:15.560,0:34:19.040
So the claim is that for 
every single entry of these,

0:34:21.000,0:34:24.660
this entry times this entry equals 
-- minus this entry equals zero.

0:34:24.660,0:34:25.600
Tracy: Equals zero. Yeah.

0:34:25.600,0:34:27.080
Justin: Okay.

0:34:27.080,0:34:29.480
And so you have to do a little mental gymnastics.

0:34:29.480,0:34:34.040
Like, rather than thinking 
of a as a vector of length m,

0:34:34.040,0:34:38.320
we want to think of it as a function 
whose domain is 0,1 to the log m.

0:34:38.320,0:34:39.060
Tracy: Yeah.

0:34:39.060,0:34:41.360
Justin: Okay. And this is a 
very natural thing to do where

0:34:41.360,0:34:46.640
rather than indexing the elements of 
a by integers between 0 and m minus 1,

0:34:46.640,0:34:48.440
we index them by bit vectors,

0:34:48.440,0:34:50.980
just the binary representations of the integers.

0:34:50.980,0:34:51.920
Tracy: Yeah.
Justin: So now we're going to ---

0:34:51.920,0:34:59.760
So we're viewing a as a function 
whose domain is {0,1} to the log m.

0:34:59.760,0:35:03.680
Tracy: So there, if you look at 
all combinations of bit vectors,

0:35:03.680,0:35:06.580
you can choose out of this, any given constraint.

0:35:06.580,0:35:07.520
Justin: Exactly.

0:35:07.520,0:35:12.960
So as a concrete example of size 4,

0:35:13.480,0:35:23.513
if this is a, we'd have a(0,0) = 2,
a(0,1) = 3, a(1,0) = 4, and a(1,1) = 5.

0:35:23.513,0:35:24.160
Tracy: Yeah.

0:35:24.160,0:35:25.040
Justin: Right?

0:35:25.040,0:35:28.420
We're just indexing the entries of a 
by bit vectors instead of integers.

0:35:28.420,0:35:30.840
Tracy: Yeah. So this is length 2ⁿ,

0:35:30.840,0:35:34.200
and as a result you have two 
entries to index all of it.

0:35:34.200,0:35:34.600
Yeah.

0:35:34.600,0:35:35.520
Justin: Yeah. Exactly.

0:35:35.520,0:35:37.520
So, yeah, this has size capital M,

0:35:37.520,0:35:43.680
and the number of variables we're 
feeding into a now is log of that.

0:35:43.680,0:35:44.560
Tracy: Yeah.

0:35:44.560,0:35:45.840
Justin: Great.

0:35:45.840,0:35:51.080
And now the beautiful thing about 
functions defined over {0,1} to the anything

0:35:51.080,0:35:53.680
is they always have a unique 
multilinear extension.

0:35:53.680,0:35:59.300
So if I stick a twiddle over a, I mean, we're now 
talking about as multilinear extension polynomial.

0:35:59.300,0:35:59.312
Tracy: Yeah.

0:35:59.312,0:36:04.920
Justin: Okay. And so if you want 
a Sum-Check-based SNARK for R1CS,

0:36:04.920,0:36:07.120
and there is one called Spartan,

0:36:08.400,0:36:11.040
essentially the first Sum-Check 
is applied to a polynomial

0:36:11.040,0:36:13.960
and I'll tell you what it is in a -- momentarily,

0:36:14.680,0:36:20.520
that just captures this equality here,

0:36:20.520,0:36:24.200
But, you know, is replacing a, b and 
c with their multilinear extensions,

0:36:24.200,0:36:28.200
because Sum-Check needs multivariate 
polynomials to apply to.

0:36:28.200,0:36:31.300
Tracy: So you do a transformation, 
get the multilinear extensions?

0:36:31.300,0:36:31.960
Justin: Right.

0:36:31.960,0:36:33.820
Tracy: And then you can 
evaluate it with Sum-Check.

0:36:33.820,0:36:34.720
Justin: Right.

0:36:34.720,0:36:37.120
And so conceptually, what's going 
to happen in the Sum-Check is

0:36:37.120,0:36:42.080
round one is going to kind of 
split a, b and c into two halves

0:36:42.680,0:36:47.000
and make sure that the two 
halves are consistent with

0:36:47.000,0:36:49.440
this right-hand side being zero as claimed.

0:36:49.440,0:36:51.680
And then just fold the two 
halves on top of each other.

0:36:51.680,0:36:55.240
So round two, you're left with 
three vectors of half the length.

0:36:55.240,0:36:56.153
And then round two --

0:36:56.153,0:36:58.600
Tracy: You do this by fixing one of the variables.

0:36:58.600,0:36:59.200
Justin: Yeah.

0:37:00.440,0:37:02.480
To a random value. Exactly.

0:37:02.480,0:37:03.280
So that's it.

0:37:03.280,0:37:07.440
And again, the benefit of 
Sum-Check over a lot of the SNARKs

0:37:07.440,0:37:10.680
that actually are currently more popular today

0:37:10.680,0:37:13.280
is there's no commitment 
costs in Sum-Check itself.

0:37:13.280,0:37:18.040
The prover is just like adding up 
and multiplying field elements.

0:37:18.040,0:37:19.120
So if you compare to --

0:37:19.120,0:37:23.840
So like Marlin is a SNARK that does 
not use multivariate polynomials,

0:37:23.840,0:37:27.040
it uses univariate ones and 
it was described for R1CS.

0:37:27.040,0:37:27.400
So it --

0:37:27.400,0:37:33.360
Like it maps very cleanly into the same 
setting as what we're talking about here.

0:37:33.360,0:37:38.480
And the very first thing Marlin will do is have 
the prover commit to these vectors a, b and c.

0:37:38.480,0:37:38.960
Tracy: Yeah.

0:37:38.960,0:37:42.060
So you have to go through all n 
terms to do the commitment. Yeah?

0:37:42.060,0:37:42.720
Justin: Right.

0:37:42.720,0:37:48.520
And committing to things is expensive, 
and exactly how expensive it varies.

0:37:48.520,0:37:52.080
But certainly if you don't have to commit 
to it, that's generally a good thing.

0:37:52.080,0:37:55.280
Tracy: I guess one difference 
there is once you've committed,  

0:37:55.280,0:37:57.440
you can do constant work in the verifier.

0:37:57.440,0:37:58.360
Justin: Right.

0:37:58.360,0:38:01.747
Tracy: Versus in Sum-Check, you're 
doing log n work in the verifier.

0:38:01.747,0:38:02.600
Justin: Yes. Yes.

0:38:02.600,0:38:08.720
Yeah. So yeah, if you really want constant 
size proofs, you really can't use Sum-Check.

0:38:08.720,0:38:10.338
You're always going to get log work.

0:38:10.338,0:38:10.560
Tracy: Got it.
Justin: Okay.

0:38:10.560,0:38:13.160
But if you're going to have 
sort of polylog-sized proofs

0:38:13.160,0:38:16.080
from using a hashing-based commitment 
scheme like FRI or something,

0:38:16.080,0:38:17.520
you're going to have polylog anyway.

0:38:17.520,0:38:19.307
The log isn't really going to matter.

0:38:19.307,0:38:19.320
Tracy: Right.

0:38:19.320,0:38:22.060
And this gets more efficient than having 
to commit all of that information.

0:38:22.060,0:38:23.000
Justin: Right, right.

0:38:23.000,0:38:25.360
And you don't really have to 
check that the committed data,

0:38:25.360,0:38:26.960
you know, the more data you commit --

0:38:26.960,0:38:28.240
any data that's committed,

0:38:28.240,0:38:32.440
you ultimately have to prove that like the 
data inside the commitment is like well formed.

0:38:32.440,0:38:33.680
So it's not just committing the data,

0:38:33.680,0:38:37.320
it's also proving that all that 
extra committed data is like "kosher".

0:38:37.320,0:38:38.360
Tracy: Yeah.

0:38:38.360,0:38:41.240
Justin: Yeah. Then another nice thing is,

0:38:41.240,0:38:46.480
SNARKs that avoid multivariate 
polynomials and just use univariate ones,

0:38:47.000,0:38:52.600
somewhere in the protocol there's typically 
what's called a quotient polynomial.

0:38:53.320,0:38:58.440
And that quotient polynomial like, you might 
or might not have to explicitly compute

0:38:58.440,0:39:01.600
that polynomial if you're the prover.

0:39:01.600,0:39:03.200
But with Sum-Check, there's --

0:39:03.200,0:39:07.200
there's just no -- there's no 
quotienting. You're only ever summing,

0:39:07.200,0:39:10.600
You know, even if you don't 
compute the quotient polynomial,

0:39:10.600,0:39:14.760
even if you don't commit to it, 
the quotient polynomials values,

0:39:14.760,0:39:16.760
you kind of don't have any control over.

0:39:16.760,0:39:19.960
So even if all of the entries 
in a, b and c are small,

0:39:19.960,0:39:23.360
once you have a quotient in there, 
the values of the quotient get big.

0:39:23.360,0:39:28.000
And so, yeah, you just like have 
fewer commitments and fewer divisions

0:39:28.000,0:39:32.200
and smaller values if you're 
using this multivariate stuff.

0:39:32.200,0:39:33.632
Tracy: Okay.

0:39:33.632,0:39:37.140
Justin: So wrapping up exactly 
formally what happens in --

0:39:37.140,0:39:37.680
So this is --

0:39:37.680,0:39:42.760
I'm sketching the Spartan 
kind of SNARK polynomial IOP.

0:39:42.760,0:39:44.120
I just do a quick --

0:39:44.120,0:39:47.920
This was why I introduced this equality polynomial

0:39:47.920,0:39:52.920
in sort of the first session of this presentation.

0:39:54.240,0:40:00.320
So I just need one basic fact about 
polynomials, which is the following.

0:40:00.320,0:40:12.760
So let g(x) be any n-variate polynomial,

0:40:14.360,0:40:16.720
Let's say of --

0:40:16.720,0:40:17.680
I should leave it like that.

0:40:17.680,0:40:24.600
And not necessarily multilinear.

0:40:24.600,0:40:27.320
Just to be clear about that.

0:40:28.600,0:40:47.720
Okay. Let p(x) be the unique 
multilinear polynomial that does this,

0:40:47.720,0:40:49.000
you know, agrees with g.

0:40:49.000,0:40:54.880
That is, has the same input output 
behavior over Boolean inputs.

0:40:54.880,0:40:57.839
Remember, like I give you any input-output
behavior over the Boolean hypercube,

0:40:57.839,0:41:00.872
there's a unique multilinear polynomial 
that has that behavior.

0:41:04.851,0:41:05.697
 Okay?

0:41:05.697,0:41:14.777
Then we can express p, that's p(r).

0:41:15.080,0:41:27.240
You know, this is n variables in r as 
the sum over x in {0,1}ⁿ

0:41:27.800,0:41:33.680
of eq(x,r) * g(x). Okay?

0:41:33.680,0:41:34.200
All right.

0:41:34.200,0:41:38.440
So the way to check that this is true is

0:41:38.440,0:41:41.480
we did this once before when I 
defined the equality polynomial.

0:41:41.480,0:41:45.160
You need to make sure that the 
right-hand side is multilinear

0:41:45.160,0:41:48.360
and that it agrees with g at any r that's Boolean --

0:41:48.360,0:41:51.240
that only takes 0,1 coordinates.

0:41:51.240,0:41:51.960
Tracy: Okay.

0:41:51.960,0:41:52.600
Justin: Okay.

0:41:52.600,0:41:56.120
And what's happening is it's 
clearly multilinear because

0:41:56.120,0:42:00.900
we're only feeding r into this equality 
thing, which is defined to be multilinear.

0:42:00.900,0:42:00.912
Tracy: Yeah.

0:42:00.912,0:42:04.120
Justin: And then to understand 
its input output behavior, right?

0:42:04.120,0:42:10.080
Like if r only has 0,1 coordinates, 
the whole point of eq is,

0:42:10.080,0:42:15.520
you're summing over all Boolean inputs, 
but only one of them is going to equal r.

0:42:15.520,0:42:17.960
And so every term of the sum dies 
except the one you care about,

0:42:17.960,0:42:20.940
and then you spit out g at that term.

0:42:20.940,0:42:20.952
Tracy: Yeah.

0:42:20.952,0:42:23.920
Justin: Okay. So this is some kind 
of multilinearization expression

0:42:23.920,0:42:30.700
where g might not be multilinear, but I can 
sort of pretend it is by looking at this thing.

0:42:30.700,0:42:34.760
Tracy: Right. By just extracting one 
piece of g and zeroing everything else.

0:42:34.760,0:42:36.160
Justin: Yeah. Something like that.

0:42:36.160,0:42:37.760
This is sort of taking like --

0:42:37.760,0:42:39.880
if r is chosen at random --

0:42:39.880,0:42:42.440
So ultimately the verifier will 
choose r at random somewhere.

0:42:42.440,0:42:43.800
Tracy: I see.

0:42:43.800,0:42:46.240
Justin: Then this is taking some funny --

0:42:46.240,0:42:49.920
It's like summing up the 
evaluations of g over the hypercube,

0:42:49.920,0:42:52.480
but each one is multiplied by some funny term.

0:42:52.480,0:42:54.680
And it's like, so if --

0:42:54.680,0:43:03.480
Yeah, and that's how you get rid of the 
non-multilinear parts of g in that way.

0:43:03.480,0:43:04.320
Tracy: Okay.

0:43:04.320,0:43:09.640
Justin: So yeah, the picture of how 
Spartan works is what I told you before,

0:43:09.640,0:43:16.040
where you take a, b and c and sort of collapse 
them in half, round over round over round.

0:43:16.040,0:43:19.680
But now I'm just going to fully tell 
you the -- like, what do we actually --

0:43:19.680,0:43:22.200
What polynomial do we apply Sum-Check to?

0:43:22.200,0:43:24.480
Yeah.
So we just covered this fact

0:43:24.480,0:43:29.920
which let us express the evaluations 
of the unique multilinear polynomial

0:43:29.920,0:43:36.440
that agrees with g over Boolean inputs 
as a nice sum of evaluations of g.

0:43:36.440,0:43:36.800
Okay.

0:43:36.800,0:43:40.560
And so sums like this are exactly what 
Sum-Check was designed to compute.

0:43:40.560,0:43:44.040
So I'm pretty happy that we were 
able to describe the evaluations of p

0:43:44.040,0:43:46.580
in terms of the evaluations 
of g in this sort of form.

0:43:46.580,0:43:47.080
Tracy: Right.

0:43:47.080,0:43:47.440
Justin: Okay.

0:43:47.440,0:43:52.040
So let's get back to Spartan and say 
exactly what does it apply Sum-Check to?

0:43:52.040,0:43:56.800
So the polynomial g we wind 
up caring about in Spartan is

0:43:56.800,0:44:00.200
the multilinear extension of a 
times the multilinear extension  

0:44:00.200,0:44:03.320
to b minus the multilinear extension to c.

0:44:03.320,0:44:05.080
Okay.
So what the prover's claiming --

0:44:05.080,0:44:09.360
You know, when the prover says that 
the R1CS constraints are all satisfied,

0:44:09.360,0:44:21.120
that's equivalent to saying that g(x)=0
for all x in {0,1} to the log m.

0:44:21.120,0:44:21.720
Right?

0:44:21.720,0:44:24.040
You know, each x is indexing 
like a constraint here.

0:44:24.040,0:44:26.880
And this is saying the x-th 
constraint is satisfied.

0:44:26.880,0:44:33.620
Yeah. But g is not multilinear because 
of the multiplication operation here.

0:44:33.620,0:44:34.592
Tracy: Yeah. I see.

0:44:34.592,0:44:35.400
Justin: Okay.

0:44:35.400,0:44:43.600
Now let's just take one more break and 
observe that like, if g were multilinear,

0:44:43.600,0:44:47.240
it's not, but if it were multilinear,

0:44:47.240,0:44:57.040
okay, then this claim is equivalent 
to g is the zero polynomial.

0:44:58.320,0:45:02.080
Because the zero polynomial is multilinear

0:45:03.160,0:45:07.720
and it has this behavior of all 
points in the Boolean hypercube.

0:45:07.720,0:45:09.560
And that's unique.

0:45:09.560,0:45:10.640
Tracy: Right.

0:45:10.640,0:45:11.320
Justin: Okay.

0:45:11.320,0:45:11.633
So --

0:45:11.633,0:45:15.200
Tracy: So this is the technique you were 
explaining of using the equality multilinear.

0:45:15.200,0:45:15.960
Justin: Exactly.

0:45:15.960,0:45:19.640
So if g were multilinear, it'd be enough for 
the verifier to just pick a random point,

0:45:19.640,0:45:21.360
evaluate g at that point.

0:45:21.360,0:45:23.880
You know, if the provers honest, it'll spit out 0.

0:45:23.880,0:45:27.240
And if it's dishonest, g won't 
be the zero polynomial, and it  

0:45:27.240,0:45:29.520
won't spit out 0 with overrunning probability.

0:45:29.520,0:45:33.200
The problem is g is not multilinear. 
That's what this is for.

0:45:33.200,0:45:34.680
Okay. So here's Spartan.

0:45:34.680,0:45:41.640
So V picks, you know, r in 
field of the log m at random.

0:45:41.640,0:45:43.680
You know, sends r to the prover.

0:45:43.680,0:45:45.000
Tracy: Yeah.

0:45:45.000,0:45:45.680
Justin: Okay.

0:45:45.680,0:45:50.280
And then they just apply 
Sum-Check. Maybe r -- or r.

0:45:50.280,0:45:59.440
Yeah, apply Sum-Check to confirm that p(r)=0.

0:45:59.440,0:46:02.000
And what is p(r)?

0:46:02.000,0:46:05.800
So that is sum --

0:46:05.800,0:46:14.960
It's right over there. But x and {0,1} to 
the log m, of eq twiddle (x,r) comma g(x).

0:46:14.960,0:46:17.040
Okay. And --

0:46:17.040,0:46:19.720
Great. So that's what Spartan does.

0:46:19.720,0:46:20.520
Tracy: Awesome.

0:46:20.520,0:46:22.160
Justin: Now, at the end of this Sum-Check,

0:46:22.160,0:46:26.320
the verifier has to evaluate this 
polynomial at a random point.

0:46:26.320,0:46:28.400
Which requires evaluating g at a random point.

0:46:28.400,0:46:28.960
Tracy: Yep.

0:46:28.960,0:46:31.840
Justin: Okay. Now that is a little bit annoying

0:46:31.840,0:46:35.339
because the verifier doesn't know what 
little a, little b, and little c are.

0:46:35.339,0:46:35.480
Tracy: Right.
Justin: Okay.

0:46:35.480,0:46:40.360
But it turns out you can get the one 
evaluation of each of these that you need

0:46:40.360,0:46:42.613
with the second Sum-Check.

0:46:42.613,0:46:42.920
Tracy: Interesting.
Justin: Okay.

0:46:42.920,0:46:44.360
And at the end of the second Sum-Check,

0:46:44.360,0:46:48.240
the verifier winds up having to 
evaluate just z at a random point.

0:46:48.240,0:46:52.600
And this z would have been committed 
at the start of the protocol

0:46:52.600,0:46:56.020
with a scheme that would let the 
evaluation come from the commitment scheme.

0:46:56.020,0:46:57.320
Tracy: I see.

0:46:57.320,0:46:59.600
Justin: And so, yeah, the 
nice thing about Spartan,

0:46:59.600,0:47:03.240
relative to SNARKs that don't use Sum-Check, 
that only use univariate polynomials,

0:47:03.240,0:47:05.680
is only z is getting committed.

0:47:05.680,0:47:07.800
Not little a, little b, little c.

0:47:07.800,0:47:09.120
There's no quotient polynomials.

0:47:09.120,0:47:13.460
Tracy: You're committing the witness, but 
you're not required to commit the full circuit.

0:47:13.460,0:47:14.240
Justin: Yeah.

0:47:14.240,0:47:17.800
Like not the value for every 
constraint, just the witness.

0:47:17.800,0:47:19.680
And you kind of -- yeah.

0:47:19.680,0:47:20.120
Yeah.

0:47:20.120,0:47:22.360
Tracy: Which reduces the provers work.

0:47:22.360,0:47:23.200
Justin: Yeah.

0:47:23.200,0:47:25.920
And in fact, it's now known that the prover in  

0:47:25.920,0:47:31.880
this Sum-Check can be brought 
down to 5 m field operations.

0:47:31.880,0:47:33.900
That 5 is, like really small.

0:47:33.900,0:47:36.080
Tracy: Yeah.
Justin: Like Nothing else really matches that.

0:47:36.080,0:47:39.760
So it uses some optimizations 
that are very recent,  

0:47:39.760,0:47:43.040
but even before those it was 10 m or something.

0:47:43.040,0:47:45.280
So, yeah, there's just like --

0:47:45.280,0:47:51.520
5 m field ops is like nothing relative 
to most of SNARKs that are used today.

0:47:52.080,0:47:53.280
Yeah.
So that's Spartan.

0:47:53.280,0:47:56.520
Tracy: Cool. And I guess we're 
going to talk a little bit about GKR

0:47:56.520,0:47:59.840
and maybe contrast some of these techniques --

0:47:59.840,0:48:02.600
this technique specifically with some 
other techniques that exist for SNARKs.

0:48:02.600,0:48:03.680
Justin: Yes. Exactly.

0:48:03.680,0:48:09.240
So Spartan is one Sum-Check-based 
SNARK, and GKR is --

0:48:09.240,0:48:11.640
Well, it's actually an interactive 
proof that uses Sum-Check Protocol

0:48:11.640,0:48:15.000
that you can turn into a SNARK by 
combining it with a commitment scheme.

0:48:15.000,0:48:15.760
Tracy: Okay.

0:48:15.760,0:48:19.920
Justin: And I think it's 
instructive to compare the two

0:48:21.160,0:48:26.400
because GKR is kind of taking the 
Sum-Check ethos to an extreme,

0:48:26.400,0:48:30.400
like really, really, really minimizing 
the amount of committed data.

0:48:30.400,0:48:36.160
Which is really powerful in certain applications, 
but can come with downsides in others.

0:48:36.160,0:48:37.520
So we can talk about that a bit.

0:48:37.520,0:48:38.100
Tracy: Okay

0:48:38.680,0:48:40.440
Justin: Okay.

0:48:42.200,0:48:45.160
So the GKR Protocol,

0:48:45.160,0:48:50.320
named for Goldwasser, Kalai, and 
Rothblum, who introduced it in 2008,

0:48:51.040,0:48:56.400
is sort of best described in the 
context of circuits rather than R1CS.

0:48:56.400,0:49:01.480
So this is just like the inputs 
to the circuit are field elements

0:49:01.480,0:49:08.280
and the gates of the circuit, each gate sort of 
adds or multiplies two field elements together.

0:49:08.280,0:49:08.820
Tracy: Yeah.

0:49:08.820,0:49:09.455
Justin: Okay.

0:49:09.455,0:49:11.611
Tracy: It's more reminiscent of Plonk than R1Cs.

0:49:11.611,0:49:15.560
Justin: Right. So Plonk was originally 
described for circuits as well.

0:49:16.240,0:49:23.080
And if you applied Spartan to a 
circuit, we described it for R1CS,

0:49:23.080,0:49:25.720
but you can apply it naturally to a circuit.

0:49:25.720,0:49:29.280
In fact, that's basically an 
earlier work called Clover.

0:49:29.280,0:49:31.080
The very first thing the prover would do is

0:49:31.080,0:49:34.395
cryptographically commit to the 
value of every gate in the circuit.

0:49:34.752,0:49:35.540
Tracy: I see.

0:49:35.540,0:49:40.440
Justin: Okay. And then Spartan just has like two Sum-Checks.

0:49:40.440,0:49:40.640
Okay.

0:49:40.640,0:49:46.480
And actually, in applications like 
Jolt, you only need one Sum-Check.

0:49:46.480,0:49:49.240
So it's kind of proving the 
whole circuit all at once.

0:49:49.240,0:49:49.840
Tracy: Yeah.

0:49:49.840,0:49:50.440
Justin: Okay.

0:49:50.440,0:49:56.640
In the GKR Protocol, the prover 
never commits to anything.

0:49:57.520,0:50:03.080
The verifier does need to ultimately evaluate 
the input to the circuit at a random point.

0:50:03.080,0:50:04.720
It's multilinear extension.

0:50:04.720,0:50:08.560
And so if the verifier knows 
x, the input to the circuit,

0:50:08.560,0:50:10.640
there's no cryptography in the GKR Protocol.

0:50:10.640,0:50:11.280
Tracy: Got it.

0:50:11.280,0:50:13.640
Justin: It's an interactive proof.

0:50:13.640,0:50:15.200
There's no committing to anything.

0:50:15.200,0:50:16.540
It's information theoretically sound.

0:50:16.540,0:50:20.240
Tracy: Right. So contrasting that to FRI or KZG,

0:50:20.240,0:50:25.040
both make cryptographic commitments which 
depend on different cryptographic constructions.

0:50:25.040,0:50:26.000
Justin: Right.

0:50:26.000,0:50:30.600
And so, you know, any SNARK 
is typically obtained by

0:50:30.600,0:50:33.160
combining a polynomial IOP and 
a polynomial commitment scheme.

0:50:33.160,0:50:37.960
And FRI and KZG are the commitment 
schemes. They're examples of them.

0:50:38.600,0:50:42.320
And so Spartan would also need 
a commitment scheme like that

0:50:42.320,0:50:47.120
and any commitment scheme, like if 
you can compute a discrete logarithm,

0:50:47.120,0:50:49.880
if you're an attacker and you 
can compute discrete logarithms,

0:50:49.880,0:50:52.480
or if you can like find 
collisions and hash functions,

0:50:52.480,0:50:54.280
you can break binding of the commitment scheme,

0:50:54.280,0:50:57.320
and therefore, find convincing proofs 
of false statements in the SNARK.

0:50:57.320,0:50:57.960
Tracy: Right.

0:50:57.960,0:50:58.680
Justin: Okay.

0:50:58.680,0:51:02.020
GKR, if the verifier knows the 
input to the circuit, there just --

0:51:02.020,0:51:07.080
There's no cryptography, so there's no hash 
function for the adversary to try to break.

0:51:07.080,0:51:09.120
You know, the adversary could 
take trillions of years.

0:51:09.120,0:51:12.520
And if you run the protocol interactively anyway,

0:51:12.520,0:51:17.400
the security is coming from the fact that 
in round i of the Sum-Check Protocol,

0:51:17.400,0:51:22.880
when the prover sends its degree 3 polynomial, 
it does not know the random point rᵢ,

0:51:22.880,0:51:27.460
that the verifier is going to pick in 
that round to like check its claim at.

0:51:27.460,0:51:28.080
Tracy: I see.

0:51:28.080,0:51:30.440
Justin: So in the Sum-Check Protocol,

0:51:30.440,0:51:34.880
it's like the security is coming from 
non-predictability of the verifier challenge,

0:51:34.880,0:51:37.000
and there's no security coming from it.

0:51:37.000,0:51:39.320
There's no cryptography hash 
functions groups anywhere.

0:51:39.320,0:51:40.720
Tracy: I see.

0:51:40.720,0:51:45.000
Justin: Now, in SNARK applications, 
often the verifier won't know x,

0:51:45.000,0:51:46.480
and so x will be committed,

0:51:47.080,0:51:51.140
but the gates of the circuit
values don't have to be committed.

0:51:51.140,0:51:54.480
Tracy: And one of the appeals of that is that the

0:51:54.480,0:52:00.140
amount of work that the prover needs to 
do is linear instead of being n log n.

0:52:00.140,0:52:02.520
Justin: Yeah. So it depends what
commitment scheme we're talking about

0:52:02.520,0:52:06.400
to discuss how expensive would these 
commitments be if we did commit.

0:52:07.200,0:52:14.040
But generally speaking, like the field operations 
that the Sum-Check prover does are cheaper.

0:52:14.560,0:52:17.720
Like group operations are built 
out of field operations. Right?

0:52:17.720,0:52:23.160
And if you avoid groups, you're going 
to have to do things like hashes or FFTs

0:52:23.160,0:52:26.120
and like one hash or --

0:52:26.120,0:52:29.419
it's all just much more expensive than 
adding or multiplying two field elements.

0:52:29.419,0:52:31.240
Tracy: Right.
Justin: That's the intuition.

0:52:31.760,0:52:35.280
And now everything is very complicated in 
practice, but that's roughly what's happening.

0:52:35.280,0:52:39.920
The downside of having no commitments at all,

0:52:39.920,0:52:43.000
even if the verifier does know 
x, there can be downsides,

0:52:43.000,0:52:48.640
is it can be pretty hard or 
impossible to keep the circuit small.

0:52:48.640,0:52:52.080
So there are general techniques 
for keeping circuits small

0:52:52.080,0:52:55.960
so that we apply SNARKs to small 
circuits instead of huge circuits,

0:52:56.520,0:52:58.680
uses a lot of untrusted advice.

0:52:58.680,0:53:02.200
And this means, if you need 
to divide two quantities,

0:53:02.200,0:53:05.080
rather than having the circuit 
literally run a division algorithm,

0:53:05.080,0:53:07.480
we have the prover provide 
the quotient and remainder,

0:53:07.480,0:53:12.080
and the circuit just checks that they're correct 
with like, one multiplication, one addition.

0:53:12.720,0:53:14.960
Now, if there's no commitment scheme,

0:53:14.960,0:53:18.760
that untrusted advice either has to 
be sent explicitly to the verifier.

0:53:18.760,0:53:23.000
But fortunately, a lot of the circuits 
we wind up caring about in SNARK design,

0:53:23.000,0:53:24.320
they're very simple.

0:53:24.320,0:53:30.160
Even without any untrusted advice, they're just 
like a binary tree of multiplication gates.

0:53:30.160,0:53:31.280
This is called a "grand product".

0:53:31.280,0:53:32.080
If you want --

0:53:32.080,0:53:36.640
If you just want to compute the product of 
all entries of x, I don't need any advice.

0:53:36.640,0:53:39.040
I'm just going to multiply them 
together in a tree and that's it.

0:53:39.040,0:53:39.952
Tracy: I see.

0:53:39.952,0:53:42.620
Justin: And that's exactly where 
we're starting to see GKR get applied.

0:53:42.620,0:53:43.200
Tracy: Okay.

0:53:43.200,0:53:46.200
Justin: Let's actually just see a binary 
tree multiplication gates real fast.

0:53:46.200,0:53:51.600
So we have x₁, x₂, x₃, x₄.

0:53:51.600,0:53:54.360
So we want to multiply these four things together.

0:53:54.360,0:53:56.440
So here's our circuit that does it.

0:53:57.760,0:53:58.240
Okay.

0:53:58.240,0:54:01.600
And the way the GKR Protocol works is like,

0:54:01.600,0:54:05.800
the prover is going to send the 
value of this claimed output gate.

0:54:05.800,0:54:06.680
Tracy: Yep.

0:54:06.680,0:54:09.280
Justin: The verifier doesn't trust that claim,

0:54:09.280,0:54:14.160
so it's going to apply the Sum-Check 
Protocol to reduce the claim about the output

0:54:14.160,0:54:17.520
to a claim about the gates 
feeding into the output.

0:54:18.400,0:54:22.880
Now, in this tiny picture, like, 
you can compute those gates,

0:54:22.880,0:54:24.280
you know, the circuit's so small,

0:54:24.280,0:54:27.200
maybe the verifier is willing to actually 
compute those gate values itself,

0:54:27.200,0:54:28.320
and check the claim.

0:54:28.320,0:54:29.920
Tracy: But if this tree is very large.

0:54:29.920,0:54:33.240
Justin: The verifier doesn't 
want to do all the work

0:54:33.240,0:54:35.880
to compute the values of the 
gates feeding into the output.

0:54:35.880,0:54:38.520
So you're not happy with that,

0:54:38.520,0:54:41.240
just as the verifier wasn't happy 
at the end of round one of Sum-Check,

0:54:41.240,0:54:42.720
it continued to the next round.

0:54:42.720,0:54:46.480
So you'd apply Sum-Check again to reduce a 
claim about these gates to a claim about --

0:54:46.480,0:54:47.760
Well, in this case, it's the input,

0:54:47.760,0:54:51.200
but in general would be like the next layer 
and the next layer and the next layer.

0:54:51.720,0:54:55.720
So for this grand product context anyway,

0:54:55.720,0:55:01.280
the proof size, you wind up applying the 
Sum-Check Protocol once per layer of the circuit,

0:55:01.280,0:55:05.000
but there's logarithmically, many 
layers of the circuit log in the  

0:55:05.000,0:55:07.640
number of things we're multiplying together.

0:55:07.640,0:55:11.360
So the proof size is log squared.

0:55:11.360,0:55:11.865
Okay.

0:55:11.865,0:55:12.705
Tracy: I see. Okay.

0:55:12.960,0:55:19.280
Justin: Which is, in practice, 
maybe 10 kilobytes-ish.

0:55:19.280,0:55:24.427
So not as short as like KZG proofs, but 
much shorter than FRI proofs or something.

0:55:24.427,0:55:25.120
Tracy: Yeah. Pretty efficient.

0:55:25.120,0:55:29.960
Justin: That's the high level. And --

0:55:30.800,0:55:36.040
Yeah, whether or not this is 
a major speed up over Spartan,

0:55:36.040,0:55:41.480
there's sort of a trade-off between the 
verifier cost compared to Spartan are going up,

0:55:41.480,0:55:43.560
but the prover costs are potentially going down

0:55:43.560,0:55:47.960
largely because you don't have to 
commit to the interior gate values.

0:55:47.960,0:55:51.520
Tracy: And for some circuits 
that trade-off changes

0:55:51.520,0:55:52.960
because you have to have a whole bunch of  

0:55:52.960,0:55:56.720
additional witness or advice in 
order to evaluate the circuit.

0:55:56.720,0:55:57.560
Justin: Right.

0:55:57.560,0:56:02.920
So if you weren't just producting all your 
inputs together and that's all the circuit did,

0:56:02.920,0:56:04.000
it might be --

0:56:04.000,0:56:05.840
You might not have a way to keep the circuit small

0:56:05.840,0:56:08.160
without having lots and lots 
of untrusted advice inputs.

0:56:08.160,0:56:11.160
And then you might as well just 
commit to everything at that point.

0:56:11.160,0:56:16.400
But these grand products seem to 
be at the heart of efficient SNARKs

0:56:16.400,0:56:18.760
and it's like perfectly suited.

0:56:18.760,0:56:22.160
You don't need any untrusted advice.

0:56:22.160,0:56:25.480
Other comments are -- well, the way 
the grand products tend to get applied,

0:56:25.480,0:56:30.200
the stuff being producted are random values,

0:56:30.200,0:56:34.040
which tends to make them 
very expensive to commit to.

0:56:34.040,0:56:40.231
Literally an order of magnitude or more costlier 
to commit to than if they were "small values".

0:56:40.231,0:56:40.840
Tracy: I see.

0:56:40.840,0:56:46.360
Justin: And so cutting out those commitments 
the way Spartan would have had you do,

0:56:46.360,0:56:48.800
can really save the prover a lot of time.

0:56:49.400,0:56:51.120
And then there are sort of hybrid approaches,

0:56:51.120,0:56:54.880
where you can get kind of most of 
the proof size benefits of Spartan

0:56:54.880,0:56:59.200
without major slowdown relative to GKR.

0:56:59.200,0:57:00.040
And then --

0:57:00.040,0:57:08.800
Yeah. So -- so Spartan is potentially a slower 
prover than GKR, but definitely smaller proofs.

0:57:09.560,0:57:13.280
And then anything that doesn't use Sum-Check,

0:57:13.280,0:57:16.760
in my view, tends to be slower than either.

0:57:16.760,0:57:17.480
Tracy: Yeah.

0:57:17.480,0:57:21.680
Justin: Because not only do they commit to 
the interior gate values of the circuit,

0:57:21.680,0:57:23.640
they commit to a bunch of other things as well.

0:57:23.640,0:57:27.440
Often there are quotient polynomials 
arising which are expensive to compute,

0:57:27.440,0:57:31.400
might or might not be explicitly committed, 
and just you avoid all of that with Sum-Check.

0:57:31.400,0:57:32.060
Tracy: Cool.

0:57:32.060,0:57:32.360
Tracy: Yeah.

0:57:32.360,0:57:35.000
The quotient polynomial on 
Plonk is particularly large

0:57:35.000,0:57:38.580
because the degree of the gates that feed into it.

0:57:38.580,0:57:39.720
Justin: Yeah. That's right.

0:57:39.720,0:57:45.960
I think Plonk does have commitment costs 
that grow with the degree of the constraints.

0:57:45.960,0:57:49.600
There are other univariate SNARKs 
that don't necessarily have that,

0:57:49.600,0:57:53.160
but there's still some quotient 
polynomial somewhere arising.

0:57:54.080,0:57:57.280
Yeah. And so there's a lot of 
components to these systems

0:57:57.280,0:58:05.800
and I view the amount of committed data as like 
a first order measure of prover efficiency.

0:58:05.800,0:58:10.520
But it's definitely not the 
case that you want to minimize  

0:58:10.520,0:58:12.640
the amount of committed data at all costs. Right?

0:58:12.640,0:58:15.600
It's definitely better to commit 
quotient and remainder than to  

0:58:15.600,0:58:17.780
have a circuit do division in the circuit. Right?

0:58:17.780,0:58:19.360
Tracy: Yeah.
Justin: So it can be a delicate balance.

0:58:19.360,0:58:23.680
But I think the SNARKs that are most 
popular today are too far to one side,

0:58:23.680,0:58:25.960
if what you care about is prover time.

0:58:26.480,0:58:30.200
And if you go way too far to the Sum-Check 
side, your circuit would be huge.

0:58:30.200,0:58:33.080
And so you want to be somewhere in the middle.

0:58:33.080,0:58:33.800
But there's a --

0:58:33.800,0:58:37.880
You know, a happy medium that 
I think we're finding now.

0:58:37.880,0:58:39.120
Tracy: Cool. Awesome.

0:58:39.120,0:58:40.780
That's a great overview. 
Thanks for taking the time!

0:58:40.780,0:58:41.694
Justin: Thanks for having me!
